(info) Number of threads: 16
(info) Preparing data...
(debug) no cache loaded.
(debug) Ignored "data/train.csv".
(info) Processing "data/fold_0"...
(debug) in preprocessing...
(debug) batch_per_epoch=27
(debug) [0] train:    loss=45.61209217707316,min=1e+99
(debug) [0] validate: tn=185,fp=3/tp=0,fn=14. roc=0.7792553191489362,prc=0.14342395021593696,fβ=0.0
(debug) [0] watcher: maximal=(0.7792553191489362, 0.14342395021593696),count=1
(debug) [0] epoch time=8.235s
(debug) checkpoint saved.
(debug) [1] train:    loss=0.6622730846758242,min=45.61209217707316
(debug) [1] validate: tn=89,fp=99/tp=14,fn=0. roc=0.8058510638297872,prc=0.16227293326288428,fβ=0.2204724409448819
(debug) [1] watcher: maximal=(0.8058510638297872, 0.16227293326288428),count=2
(debug) [1] epoch time=6.853s
(debug) checkpoint saved.
(debug) [2] train:    loss=0.6334993176990085,min=0.6622730846758242
(debug) [2] validate: tn=142,fp=46/tp=9,fn=5. roc=0.8411854103343465,prc=0.19253523996987443,fβ=0.2608695652173913
(debug) [2] watcher: maximal=(0.8411854103343465, 0.19253523996987443),count=3
(debug) [2] epoch time=7.524s
(debug) checkpoint saved.
(debug) [3] train:    loss=0.6020073868610241,min=0.6334993176990085
(debug) [3] validate: tn=141,fp=47/tp=11,fn=3. roc=0.847644376899696,prc=0.2008665853764816,fβ=0.3055555555555555
(debug) [3] watcher: maximal=(0.847644376899696, 0.2008665853764816),count=4
(debug) [3] epoch time=7.623s
(debug) checkpoint saved.
(debug) [4] train:    loss=0.5729763640297784,min=0.6020073868610241
(debug) [4] validate: tn=143,fp=45/tp=11,fn=3. roc=0.8453647416413375,prc=0.2016080599203307,fβ=0.3142857142857143
(debug) [4] watcher: maximal=(0.847644376899696, 0.2008665853764816),count=4
(debug) [4] epoch time=7.835s
(debug) checkpoint loaded.
(debug) in postprocessing...
(debug) tensor([[0.4982, 0.5018, 0.0000],
        [0.4841, 0.5159, 0.0000],
        [0.4671, 0.5329, 0.0000],
        [0.3388, 0.6612, 0.0000],
        [0.4313, 0.5687, 0.0000],
        [0.4918, 0.5082, 0.0000],
        [0.2421, 0.7579, 0.0000],
        [0.4515, 0.5485, 0.0000],
        [0.4208, 0.5792, 0.0000],
        [0.4872, 0.5128, 0.0000],
        [0.4555, 0.5445, 0.0000],
        [0.4253, 0.5747, 0.0000],
        [0.4976, 0.5024, 0.0000],
        [0.2133, 0.7867, 1.0000],
        [0.4442, 0.5558, 1.0000],
        [0.3801, 0.6199, 0.0000],
        [0.4655, 0.5345, 0.0000],
        [0.4806, 0.5194, 0.0000],
        [0.2942, 0.7058, 0.0000],
        [0.4835, 0.5165, 0.0000],
        [0.4811, 0.5189, 0.0000],
        [0.3419, 0.6581, 0.0000],
        [0.3900, 0.6100, 0.0000],
        [0.1137, 0.8863, 0.0000],
        [0.4364, 0.5636, 0.0000],
        [0.4749, 0.5251, 0.0000],
        [0.4852, 0.5148, 0.0000],
        [0.4899, 0.5101, 0.0000],
        [0.1692, 0.8308, 0.0000],
        [0.4925, 0.5075, 0.0000],
        [0.4648, 0.5352, 0.0000],
        [0.1447, 0.8553, 0.0000],
        [0.4648, 0.5352, 0.0000],
        [0.2171, 0.7829, 0.0000],
        [0.4698, 0.5302, 0.0000],
        [0.4829, 0.5171, 0.0000],
        [0.4589, 0.5411, 0.0000],
        [0.2425, 0.7575, 0.0000],
        [0.4815, 0.5185, 0.0000],
        [0.4794, 0.5206, 0.0000],
        [0.4557, 0.5443, 0.0000],
        [0.2700, 0.7300, 0.0000]])
(info) test: tn=156,fp=40/tp=2,fn=3
(info) ROC-AUC: 0.7040816326530612
(info) PRC-AUC: 0.06782594365645206
(info) Processing "data/fold_1"...
(debug) in preprocessing...
(debug) batch_per_epoch=27
(debug) [0] train:    loss=46.88716697692871,min=1e+99
(debug) [0] validate: tn=186,fp=11/tp=0,fn=4. roc=0.6040609137055837,prc=0.022956908338370233,fβ=0.0
(debug) [0] watcher: maximal=(0.6040609137055837, 0.022956908338370233),count=1
(debug) [0] epoch time=8.032s
(debug) checkpoint saved.
(debug) [1] train:    loss=0.6808485477058975,min=46.88716697692871
(debug) [1] validate: tn=166,fp=31/tp=1,fn=3. roc=0.8261421319796954,prc=0.055378963000893816,fβ=0.05555555555555555
(debug) [1] watcher: maximal=(0.8261421319796954, 0.055378963000893816),count=2
(debug) [1] epoch time=7.628s
(debug) checkpoint saved.
(debug) [2] train:    loss=0.6584096882078383,min=0.6808485477058975
(debug) [2] validate: tn=140,fp=57/tp=4,fn=0. roc=0.8604060913705585,prc=0.07535618976326641,fβ=0.12307692307692307
(debug) [2] watcher: maximal=(0.8604060913705585, 0.07535618976326641),count=3
(debug) [2] epoch time=7.756s
(debug) checkpoint saved.
(debug) [3] train:    loss=0.6348949361730505,min=0.6584096882078383
(debug) [3] validate: tn=138,fp=59/tp=4,fn=0. roc=0.8756345177664975,prc=0.09145827138467638,fβ=0.11940298507462686
(debug) [3] watcher: maximal=(0.8756345177664975, 0.09145827138467638),count=4
(debug) [3] epoch time=7.808s
(debug) checkpoint saved.
(debug) [4] train:    loss=0.6068314004827429,min=0.6348949361730505
(debug) [4] validate: tn=140,fp=57/tp=3,fn=1. roc=0.8781725888324874,prc=0.09592905267247373,fβ=0.09375000000000001
(debug) [4] watcher: maximal=(0.8781725888324874, 0.09592905267247373),count=5
(debug) [4] epoch time=7.350s
(debug) checkpoint saved.
(debug) checkpoint loaded.
(debug) in postprocessing...
(debug) tensor([[0.4418, 0.5582, 0.0000],
        [0.4574, 0.5426, 0.0000],
        [0.4505, 0.5495, 0.0000],
        [0.4828, 0.5172, 0.0000],
        [0.3978, 0.6022, 0.0000],
        [0.4378, 0.5622, 0.0000],
        [0.4473, 0.5527, 0.0000],
        [0.4856, 0.5144, 0.0000],
        [0.4557, 0.5443, 0.0000],
        [0.3753, 0.6247, 0.0000],
        [0.4909, 0.5091, 0.0000],
        [0.4913, 0.5087, 0.0000],
        [0.3546, 0.6454, 0.0000],
        [0.3752, 0.6248, 0.0000],
        [0.4692, 0.5308, 0.0000],
        [0.3864, 0.6136, 0.0000],
        [0.3626, 0.6374, 0.0000],
        [0.4533, 0.5467, 0.0000],
        [0.2736, 0.7264, 0.0000],
        [0.3715, 0.6285, 1.0000],
        [0.3130, 0.6870, 1.0000],
        [0.3979, 0.6021, 1.0000],
        [0.2830, 0.7170, 1.0000],
        [0.4215, 0.5785, 1.0000],
        [0.3289, 0.6711, 1.0000],
        [0.2878, 0.7122, 0.0000],
        [0.4604, 0.5396, 0.0000],
        [0.4201, 0.5799, 1.0000],
        [0.4228, 0.5772, 1.0000],
        [0.4510, 0.5490, 1.0000],
        [0.3845, 0.6155, 1.0000],
        [0.3800, 0.6200, 1.0000],
        [0.3965, 0.6035, 0.0000],
        [0.4804, 0.5196, 0.0000],
        [0.4513, 0.5487, 0.0000],
        [0.3798, 0.6202, 0.0000],
        [0.4573, 0.5427, 0.0000],
        [0.4417, 0.5583, 0.0000],
        [0.4785, 0.5215, 0.0000],
        [0.4189, 0.5811, 0.0000],
        [0.3880, 0.6120, 0.0000],
        [0.3500, 0.6500, 0.0000],
        [0.3758, 0.6242, 0.0000],
        [0.3688, 0.6312, 0.0000],
        [0.3395, 0.6605, 0.0000],
        [0.2881, 0.7119, 1.0000],
        [0.4402, 0.5598, 1.0000],
        [0.3519, 0.6481, 1.0000],
        [0.3933, 0.6067, 0.0000],
        [0.4115, 0.5885, 0.0000],
        [0.3332, 0.6668, 0.0000],
        [0.4697, 0.5303, 0.0000],
        [0.4524, 0.5476, 0.0000],
        [0.1025, 0.8975, 0.0000],
        [0.4659, 0.5341, 0.0000],
        [0.4269, 0.5731, 0.0000],
        [0.4967, 0.5033, 0.0000],
        [0.2071, 0.7929, 0.0000],
        [0.3372, 0.6628, 0.0000],
        [0.1967, 0.8033, 0.0000],
        [0.4807, 0.5193, 0.0000],
        [0.4679, 0.5321, 0.0000],
        [0.0373, 0.9627, 0.0000],
        [0.3834, 0.6166, 0.0000],
        [0.4038, 0.5962, 0.0000],
        [0.3833, 0.6167, 0.0000],
        [0.4307, 0.5693, 0.0000],
        [0.2588, 0.7412, 0.0000],
        [0.4634, 0.5366, 0.0000],
        [0.4713, 0.5287, 0.0000],
        [0.2231, 0.7769, 0.0000],
        [0.4972, 0.5028, 0.0000],
        [0.4849, 0.5151, 0.0000]])
(info) test: tn=129,fp=59/tp=14,fn=0
(info) ROC-AUC: 0.8939969604863223
(info) PRC-AUC: 0.24362602016558504
(info) Processing "data/fold_2"...
(debug) in preprocessing...
(debug) batch_per_epoch=27
(debug) [0] train:    loss=50.13561256947341,min=1e+99
(debug) [0] validate: tn=181,fp=17/tp=0,fn=4. roc=0.4154040404040404,prc=0.017061660600351386,fβ=0.0
(debug) [0] watcher: maximal=(0.4154040404040404, 0.017061660600351386),count=1
(debug) [0] epoch time=7.554s
(debug) checkpoint saved.
(debug) [1] train:    loss=0.6540560678199485,min=50.13561256947341
(debug) [1] validate: tn=133,fp=65/tp=2,fn=2. roc=0.43434343434343436,prc=0.01916205173519967,fβ=0.056338028169014086
(debug) [1] watcher: maximal=(0.43434343434343436, 0.01916205173519967),count=2
(debug) [1] epoch time=7.087s
(debug) checkpoint saved.
(debug) [2] train:    loss=0.6108409983140451,min=0.6540560678199485
(debug) [2] validate: tn=140,fp=58/tp=1,fn=3. roc=0.4368686868686869,prc=0.018708269737879812,fβ=0.031746031746031744
(debug) [2] watcher: maximal=(0.4368686868686869, 0.018708269737879812),count=3
(debug) [2] epoch time=7.460s
(debug) checkpoint saved.
(debug) [3] train:    loss=0.5852971915845517,min=0.6108409983140451
(debug) [3] validate: tn=161,fp=37/tp=1,fn=3. roc=0.4482323232323232,prc=0.019283924012925738,fβ=0.04761904761904762
(debug) [3] watcher: maximal=(0.4482323232323232, 0.019283924012925738),count=4
(debug) [3] epoch time=7.542s
(debug) checkpoint saved.
(debug) [4] train:    loss=0.5501515478999527,min=0.5852971915845517
(debug) [4] validate: tn=163,fp=35/tp=1,fn=3. roc=0.47474747474747475,prc=0.01973188773117926,fβ=0.049999999999999996
(debug) [4] watcher: maximal=(0.47474747474747475, 0.01973188773117926),count=5
(debug) [4] epoch time=7.573s
(debug) checkpoint saved.
(debug) checkpoint loaded.
(debug) in postprocessing...
(debug) tensor([[0.4771, 0.5229, 0.0000],
        [0.4768, 0.5232, 0.0000],
        [0.4619, 0.5381, 0.0000],
        [0.2215, 0.7785, 0.0000],
        [0.4488, 0.5512, 0.0000],
        [0.4983, 0.5017, 0.0000],
        [0.3445, 0.6555, 0.0000],
        [0.2718, 0.7282, 0.0000],
        [0.2718, 0.7282, 0.0000],
        [0.4861, 0.5139, 0.0000],
        [0.4603, 0.5397, 0.0000],
        [0.4104, 0.5896, 0.0000],
        [0.3854, 0.6146, 1.0000],
        [0.4206, 0.5794, 1.0000],
        [0.0373, 0.9627, 1.0000],
        [0.4071, 0.5929, 0.0000],
        [0.3553, 0.6447, 0.0000],
        [0.4047, 0.5953, 0.0000],
        [0.3946, 0.6054, 0.0000],
        [0.0134, 0.9866, 0.0000],
        [0.2360, 0.7640, 0.0000],
        [0.0152, 0.9848, 0.0000],
        [0.3861, 0.6139, 0.0000],
        [0.4894, 0.5106, 0.0000],
        [0.4743, 0.5257, 0.0000],
        [0.4119, 0.5881, 0.0000],
        [0.4365, 0.5635, 0.0000],
        [0.4607, 0.5393, 0.0000],
        [0.4681, 0.5319, 0.0000],
        [0.4423, 0.5577, 0.0000],
        [0.4656, 0.5344, 0.0000],
        [0.2607, 0.7393, 0.0000],
        [0.4574, 0.5426, 0.0000],
        [0.3616, 0.6384, 0.0000],
        [0.4961, 0.5039, 0.0000],
        [0.1537, 0.8463, 0.0000],
        [0.4811, 0.5189, 0.0000],
        [0.4922, 0.5078, 0.0000],
        [0.4970, 0.5030, 0.0000],
        [0.3770, 0.6230, 0.0000],
        [0.4833, 0.5167, 0.0000],
        [0.4709, 0.5291, 0.0000],
        [0.1183, 0.8817, 0.0000],
        [0.4468, 0.5532, 0.0000],
        [0.4655, 0.5345, 0.0000],
        [0.3354, 0.6646, 0.0000]])
(info) test: tn=154,fp=43/tp=3,fn=1
(info) ROC-AUC: 0.8083756345177665
(info) PRC-AUC: 0.10067263096368714
(info) Processing "data/fold_3"...
(debug) in preprocessing...
(debug) batch_per_epoch=27
(debug) [0] train:    loss=38.949507243103454,min=1e+99
(debug) [0] validate: tn=184,fp=11/tp=0,fn=6. roc=0.7948717948717949,prc=0.07337537688147444,fβ=0.0
(debug) [0] watcher: maximal=(0.7948717948717949, 0.07337537688147444),count=1
(debug) [0] epoch time=7.781s
(debug) checkpoint saved.
(debug) [1] train:    loss=0.63396938862624,min=38.949507243103454
(debug) [1] validate: tn=187,fp=8/tp=2,fn=4. roc=0.8324786324786324,prc=0.10640353787798992,fβ=0.25
(debug) [1] watcher: maximal=(0.8324786324786324, 0.10640353787798992),count=2
(debug) [1] epoch time=6.866s
(debug) checkpoint saved.
(debug) [2] train:    loss=0.5736399955219693,min=0.63396938862624
(debug) [2] validate: tn=157,fp=38/tp=6,fn=0. roc=0.9153846153846152,prc=0.15176410607490828,fβ=0.24000000000000002
(debug) [2] watcher: maximal=(0.9153846153846152, 0.15176410607490828),count=3
(debug) [2] epoch time=7.478s
(debug) checkpoint saved.
(debug) [3] train:    loss=0.5122242647188681,min=0.5736399955219693
(debug) [3] validate: tn=161,fp=34/tp=6,fn=0. roc=0.923931623931624,prc=0.17113211312699805,fβ=0.2608695652173913
(debug) [3] watcher: maximal=(0.923931623931624, 0.17113211312699805),count=4
(debug) [3] epoch time=7.729s
(debug) checkpoint saved.
(debug) [4] train:    loss=0.48822642145333467,min=0.5122242647188681
(debug) [4] validate: tn=158,fp=37/tp=6,fn=0. roc=0.9282051282051281,prc=0.17611240637187342,fβ=0.24489795918367346
(debug) [4] watcher: maximal=(0.9282051282051281, 0.17611240637187342),count=5
(debug) [4] epoch time=7.406s
(debug) checkpoint saved.
(debug) checkpoint loaded.
(debug) in postprocessing...
(debug) tensor([[0.4265, 0.5735, 0.0000],
        [0.4340, 0.5660, 0.0000],
        [0.4265, 0.5735, 0.0000],
        [0.4628, 0.5372, 0.0000],
        [0.4340, 0.5660, 0.0000],
        [0.4565, 0.5435, 0.0000],
        [0.4067, 0.5933, 0.0000],
        [0.4340, 0.5660, 0.0000],
        [0.4628, 0.5372, 0.0000],
        [0.3872, 0.6128, 0.0000],
        [0.3529, 0.6471, 0.0000],
        [0.3872, 0.6128, 0.0000],
        [0.4628, 0.5372, 0.0000],
        [0.4265, 0.5735, 0.0000],
        [0.3460, 0.6540, 0.0000],
        [0.4340, 0.5660, 0.0000],
        [0.3460, 0.6540, 0.0000],
        [0.0024, 0.9976, 0.0000],
        [0.4087, 0.5913, 0.0000],
        [0.4601, 0.5399, 0.0000],
        [0.4467, 0.5533, 0.0000],
        [0.4117, 0.5883, 0.0000],
        [0.1411, 0.8589, 0.0000],
        [0.2086, 0.7914, 0.0000],
        [0.2972, 0.7028, 0.0000],
        [0.4707, 0.5293, 0.0000],
        [0.2641, 0.7359, 0.0000],
        [0.3751, 0.6249, 0.0000],
        [0.3681, 0.6319, 0.0000],
        [0.2362, 0.7638, 0.0000],
        [0.4659, 0.5341, 0.0000],
        [0.1026, 0.8974, 0.0000],
        [0.4368, 0.5632, 1.0000],
        [0.4310, 0.5690, 1.0000],
        [0.2524, 0.7476, 0.0000],
        [0.4723, 0.5277, 0.0000],
        [0.4649, 0.5351, 0.0000],
        [0.3832, 0.6168, 0.0000],
        [0.2612, 0.7388, 0.0000],
        [0.3161, 0.6839, 0.0000],
        [0.3217, 0.6783, 0.0000],
        [0.4799, 0.5201, 0.0000],
        [0.4467, 0.5533, 0.0000],
        [0.3720, 0.6280, 0.0000],
        [0.4468, 0.5532, 0.0000],
        [0.2101, 0.7899, 0.0000],
        [0.3288, 0.6712, 0.0000],
        [0.0280, 0.9720, 0.0000],
        [0.2745, 0.7255, 0.0000],
        [0.2592, 0.7408, 0.0000],
        [0.4044, 0.5956, 0.0000],
        [0.3035, 0.6965, 0.0000]])
(info) test: tn=148,fp=50/tp=2,fn=2
(info) ROC-AUC: 0.6578282828282829
(info) PRC-AUC: 0.029084873939322745
(info) Processing "data/fold_4"...
(debug) in preprocessing...
(debug) batch_per_epoch=27
(debug) [0] train:    loss=52.014603444823514,min=1e+99
(debug) [0] validate: tn=10,fp=188/tp=3,fn=0. roc=0.5606060606060606,prc=0.015651081908870074,fβ=0.03092783505154639
(debug) [0] watcher: maximal=(0.5606060606060606, 0.015651081908870074),count=1
(debug) [0] epoch time=7.313s
(debug) checkpoint saved.
(debug) [1] train:    loss=0.6586887505319383,min=52.014603444823514
(debug) [1] validate: tn=169,fp=29/tp=1,fn=2. roc=0.7239057239057238,prc=0.024459098521598527,fβ=0.0606060606060606
(debug) [1] watcher: maximal=(0.7239057239057238, 0.024459098521598527),count=2
(debug) [1] epoch time=7.172s
(debug) checkpoint saved.
(debug) [2] train:    loss=0.6367821605117233,min=0.6586887505319383
(debug) [2] validate: tn=107,fp=91/tp=3,fn=0. roc=0.7643097643097643,prc=0.031344808231600685,fβ=0.06185567010309278
(debug) [2] watcher: maximal=(0.7643097643097643, 0.031344808231600685),count=3
(debug) [2] epoch time=7.537s
(debug) checkpoint saved.
(debug) [3] train:    loss=0.5953143570158217,min=0.6367821605117233
(debug) [3] validate: tn=114,fp=84/tp=3,fn=0. roc=0.7946127946127945,prc=0.035793299157269746,fβ=0.06666666666666667
(debug) [3] watcher: maximal=(0.7946127946127945, 0.035793299157269746),count=4
(debug) [3] epoch time=7.428s
(debug) checkpoint saved.
(debug) [4] train:    loss=0.5799029822702761,min=0.5953143570158217
(debug) [4] validate: tn=128,fp=70/tp=3,fn=0. roc=0.8215488215488216,prc=0.03909073712741341,fβ=0.07894736842105263
(debug) [4] watcher: maximal=(0.8215488215488216, 0.03909073712741341),count=5
(debug) [4] epoch time=7.433s
(debug) checkpoint saved.
(debug) checkpoint loaded.
(debug) in postprocessing...
(debug) tensor([[0.4235, 0.5765, 0.0000],
        [0.4543, 0.5457, 0.0000],
        [0.2676, 0.7324, 1.0000],
        [0.4435, 0.5565, 1.0000],
        [0.4711, 0.5289, 1.0000],
        [0.2249, 0.7751, 1.0000],
        [0.4678, 0.5322, 0.0000],
        [0.4139, 0.5861, 0.0000],
        [0.2703, 0.7297, 0.0000],
        [0.2742, 0.7258, 0.0000],
        [0.4894, 0.5106, 0.0000],
        [0.4297, 0.5703, 0.0000],
        [0.4278, 0.5722, 0.0000],
        [0.2755, 0.7245, 0.0000],
        [0.2058, 0.7942, 0.0000],
        [0.3897, 0.6103, 0.0000],
        [0.2946, 0.7054, 1.0000],
        [0.4186, 0.5814, 0.0000],
        [0.4906, 0.5094, 0.0000],
        [0.1696, 0.8304, 0.0000],
        [0.2929, 0.7071, 0.0000],
        [0.3992, 0.6008, 0.0000],
        [0.4649, 0.5351, 0.0000],
        [0.4402, 0.5598, 0.0000],
        [0.5000, 0.5000, 0.0000],
        [0.3916, 0.6084, 0.0000],
        [0.4541, 0.5459, 0.0000],
        [0.4742, 0.5258, 0.0000],
        [0.4278, 0.5722, 0.0000],
        [0.1774, 0.8226, 0.0000],
        [0.4785, 0.5215, 0.0000],
        [0.4086, 0.5914, 0.0000],
        [0.0207, 0.9793, 0.0000],
        [0.4475, 0.5525, 0.0000],
        [0.4231, 0.5769, 0.0000],
        [0.2755, 0.7245, 0.0000],
        [0.0315, 0.9685, 0.0000],
        [0.4096, 0.5904, 0.0000],
        [0.2339, 0.7661, 0.0000],
        [0.1551, 0.8449, 0.0000],
        [0.4342, 0.5658, 0.0000],
        [0.3485, 0.6515, 0.0000],
        [0.4397, 0.5603, 0.0000],
        [0.4370, 0.5630, 0.0000]])
(info) test: tn=156,fp=39/tp=5,fn=1
(info) ROC-AUC: 0.8589743589743589
(info) PRC-AUC: 0.11788597346925815
(info) Processing "data/fold_5"...
(debug) in preprocessing...
(debug) batch_per_epoch=26
(debug) [0] train:    loss=57.978063193651344,min=1e+99
(debug) [0] validate: tn=260,fp=14/tp=0,fn=4. roc=0.7299270072992701,prc=0.024940345535426286,fβ=0.0
(debug) [0] watcher: maximal=(0.7299270072992701, 0.024940345535426286),count=1
(debug) [0] epoch time=7.376s
(debug) checkpoint saved.
(debug) [1] train:    loss=0.6460572435305669,min=57.978063193651344
(debug) [1] validate: tn=274,fp=0/tp=0,fn=4. roc=0.635036496350365,prc=0.01906791865054678,fβ=0.0
(debug) [1] watcher: maximal=(0.7299270072992701, 0.024940345535426286),count=1
(debug) [1] epoch time=7.297s
(debug) [2] train:    loss=0.6139165438138522,min=0.6460572435305669
(debug) [2] validate: tn=273,fp=1/tp=0,fn=4. roc=0.531021897810219,prc=0.014503855742966414,fβ=0.0
(debug) [2] watcher: maximal=(0.7299270072992701, 0.024940345535426286),count=1
(debug) [2] epoch time=7.618s
(debug) [3] train:    loss=0.5723441632894369,min=0.6139165438138522
(debug) [3] validate: tn=267,fp=7/tp=0,fn=4. roc=0.42883211678832117,prc=0.011970139732874991,fβ=0.0
(debug) [3] watcher: maximal=(0.7299270072992701, 0.024940345535426286),count=1
(debug) [3] epoch time=7.403s
(debug) [4] train:    loss=0.5413920501103768,min=0.5723441632894369
(debug) [4] validate: tn=257,fp=17/tp=0,fn=4. roc=0.3895985401459854,prc=0.0108508081737197,fβ=0.0
(debug) [4] watcher: maximal=(0.7299270072992701, 0.024940345535426286),count=1
(debug) [4] epoch time=7.394s
(debug) checkpoint loaded.
(debug) in postprocessing...
(debug) tensor([[0.4488, 0.5512, 0.0000],
        [0.4923, 0.5077, 0.0000],
        [0.4744, 0.5256, 0.0000],
        [0.4706, 0.5294, 0.0000],
        [0.4511, 0.5489, 0.0000],
        [0.4421, 0.5579, 0.0000],
        [0.4662, 0.5338, 0.0000],
        [0.4421, 0.5579, 0.0000],
        [0.4450, 0.5550, 0.0000],
        [0.4211, 0.5789, 0.0000],
        [0.4623, 0.5377, 0.0000],
        [0.4950, 0.5050, 0.0000],
        [0.4990, 0.5010, 0.0000],
        [0.4912, 0.5088, 0.0000],
        [0.4795, 0.5205, 0.0000],
        [0.4396, 0.5604, 0.0000],
        [0.4619, 0.5381, 0.0000],
        [0.4862, 0.5138, 0.0000],
        [0.4319, 0.5681, 0.0000],
        [0.4414, 0.5586, 0.0000],
        [0.3964, 0.6036, 0.0000],
        [0.3991, 0.6009, 0.0000],
        [0.3983, 0.6017, 0.0000],
        [0.4039, 0.5961, 0.0000],
        [0.4900, 0.5100, 0.0000],
        [0.4723, 0.5277, 1.0000],
        [0.4709, 0.5291, 0.0000],
        [0.2559, 0.7441, 0.0000],
        [0.3978, 0.6022, 0.0000],
        [0.4703, 0.5297, 0.0000],
        [0.4306, 0.5694, 0.0000],
        [0.4826, 0.5174, 0.0000],
        [0.4449, 0.5551, 0.0000],
        [0.3874, 0.6126, 0.0000],
        [0.4968, 0.5032, 0.0000],
        [0.4321, 0.5679, 0.0000],
        [0.4931, 0.5069, 0.0000],
        [0.4653, 0.5347, 0.0000],
        [0.3947, 0.6053, 0.0000],
        [0.4602, 0.5398, 0.0000],
        [0.3108, 0.6892, 0.0000],
        [0.3844, 0.6156, 0.0000],
        [0.2809, 0.7191, 0.0000],
        [0.4583, 0.5417, 0.0000],
        [0.4514, 0.5486, 0.0000],
        [0.4400, 0.5600, 0.0000],
        [0.4539, 0.5461, 0.0000],
        [0.1515, 0.8485, 0.0000],
        [0.4025, 0.5975, 0.0000],
        [0.4518, 0.5482, 0.0000],
        [0.4278, 0.5722, 0.0000],
        [0.4497, 0.5503, 0.0000],
        [0.4780, 0.5220, 0.0000],
        [0.4644, 0.5356, 0.0000],
        [0.4754, 0.5246, 0.0000],
        [0.3855, 0.6145, 0.0000],
        [0.4299, 0.5701, 0.0000],
        [0.4738, 0.5262, 0.0000],
        [0.2996, 0.7004, 0.0000],
        [0.4970, 0.5030, 0.0000],
        [0.4962, 0.5038, 0.0000],
        [0.4955, 0.5045, 0.0000],
        [0.4176, 0.5824, 0.0000],
        [0.3012, 0.6988, 0.0000],
        [0.4515, 0.5485, 0.0000],
        [0.3837, 0.6163, 0.0000],
        [0.2008, 0.7992, 0.0000],
        [0.4605, 0.5395, 0.0000]])
(info) test: tn=131,fp=67/tp=1,fn=2
(info) ROC-AUC: 0.537037037037037
(info) PRC-AUC: 0.014732190991086143
(info) Processing "data/fold_6"...
(debug) in preprocessing...
(debug) batch_per_epoch=26
(debug) [0] train:    loss=56.820126726077156,min=1e+99
(debug) [0] validate: tn=193,fp=14/tp=0,fn=1. roc=0.5072463768115942,prc=0.0048543689320388345,fβ=0.0
(debug) [0] watcher: maximal=(0.5072463768115942, 0.0048543689320388345),count=1
(debug) [0] epoch time=7.466s
(debug) checkpoint saved.
(debug) [1] train:    loss=0.6518931961976565,min=56.820126726077156
(debug) [1] validate: tn=167,fp=40/tp=0,fn=1. roc=0.4347826086956522,prc=0.00423728813559322,fβ=0.0
(debug) [1] watcher: maximal=(0.5072463768115942, 0.0048543689320388345),count=1
(debug) [1] epoch time=7.622s
(debug) [2] train:    loss=0.6141048921988561,min=0.6518931961976565
(debug) [2] validate: tn=183,fp=24/tp=0,fn=1. roc=0.4685990338164251,prc=0.0045045045045045045,fβ=0.0
(debug) [2] watcher: maximal=(0.5072463768115942, 0.0048543689320388345),count=1
(debug) [2] epoch time=7.611s
(debug) [3] train:    loss=0.5890154059116657,min=0.6141048921988561
(debug) [3] validate: tn=187,fp=20/tp=0,fn=1. roc=0.40096618357487923,prc=0.004,fβ=0.0
(debug) [3] watcher: maximal=(0.5072463768115942, 0.0048543689320388345),count=1
(debug) [3] epoch time=7.643s
(debug) [4] train:    loss=0.5688224320228283,min=0.5890154059116657
(debug) [4] validate: tn=190,fp=17/tp=0,fn=1. roc=0.3913043478260869,prc=0.003937007874015748,fβ=0.0
(debug) [4] watcher: maximal=(0.5072463768115942, 0.0048543689320388345),count=1
(debug) [4] epoch time=7.716s
(debug) checkpoint loaded.
(debug) in postprocessing...
(debug) tensor([[0.4833, 0.5167, 0.0000],
        [0.4769, 0.5231, 0.0000],
        [0.4784, 0.5216, 0.0000]])
(info) test: tn=271,fp=3/tp=0,fn=4
(info) ROC-AUC: 0.7746350364963503
(info) PRC-AUC: 0.04766152210787031
(info) Processing "data/fold_7"...
(debug) in preprocessing...
(debug) batch_per_epoch=27
(debug) [0] train:    loss=48.12186192141639,min=1e+99
(debug) [0] validate: tn=196,fp=1/tp=0,fn=4. roc=0.717005076142132,prc=0.05757418629201941,fβ=0.0
(debug) [0] watcher: maximal=(0.717005076142132, 0.05757418629201941),count=1
(debug) [0] epoch time=7.882s
(debug) checkpoint saved.
(debug) [1] train:    loss=0.658862175764861,min=48.12186192141639
(debug) [1] validate: tn=79,fp=118/tp=4,fn=0. roc=0.7918781725888324,prc=0.13409391216605807,fβ=0.06349206349206349
(debug) [1] watcher: maximal=(0.7918781725888324, 0.13409391216605807),count=2
(debug) [1] epoch time=7.745s
(debug) checkpoint saved.
(debug) [2] train:    loss=0.6264512980425799,min=0.658862175764861
(debug) [2] validate: tn=151,fp=46/tp=3,fn=1. roc=0.8223350253807107,prc=0.1729952912149013,fβ=0.11320754716981131
(debug) [2] watcher: maximal=(0.8223350253807107, 0.1729952912149013),count=3
(debug) [2] epoch time=8.182s
(debug) checkpoint saved.
(debug) [3] train:    loss=0.5944477275565818,min=0.6264512980425799
(debug) [3] validate: tn=148,fp=49/tp=3,fn=1. roc=0.8439086294416244,prc=0.17745346993321953,fβ=0.10714285714285714
(debug) [3] watcher: maximal=(0.8439086294416244, 0.17745346993321953),count=4
(debug) [3] epoch time=8.338s
(debug) checkpoint saved.
(debug) [4] train:    loss=0.563082566967717,min=0.5944477275565818
(debug) [4] validate: tn=150,fp=47/tp=3,fn=1. roc=0.8540609137055837,prc=0.15700091575091574,fβ=0.1111111111111111
(debug) [4] watcher: maximal=(0.8540609137055837, 0.15700091575091574),count=5
(debug) [4] epoch time=8.039s
(debug) checkpoint saved.
(debug) checkpoint loaded.
(debug) in postprocessing...
(debug) tensor([[4.0663e-01, 5.9337e-01, 0.0000e+00],
        [1.9901e-01, 8.0099e-01, 0.0000e+00],
        [4.6230e-01, 5.3770e-01, 0.0000e+00],
        [3.4564e-01, 6.5436e-01, 0.0000e+00],
        [3.2535e-01, 6.7465e-01, 0.0000e+00],
        [4.7641e-01, 5.2359e-01, 0.0000e+00],
        [3.7915e-01, 6.2085e-01, 0.0000e+00],
        [4.7215e-01, 5.2785e-01, 0.0000e+00],
        [7.0319e-05, 9.9993e-01, 0.0000e+00],
        [3.5062e-01, 6.4938e-01, 0.0000e+00],
        [2.8993e-01, 7.1007e-01, 0.0000e+00],
        [4.9228e-01, 5.0772e-01, 0.0000e+00],
        [2.9002e-01, 7.0998e-01, 0.0000e+00],
        [4.3635e-01, 5.6365e-01, 0.0000e+00],
        [2.1159e-01, 7.8841e-01, 0.0000e+00],
        [2.5768e-01, 7.4232e-01, 0.0000e+00],
        [4.4157e-01, 5.5843e-01, 0.0000e+00],
        [1.6575e-01, 8.3425e-01, 0.0000e+00],
        [4.7899e-01, 5.2101e-01, 0.0000e+00],
        [3.2846e-01, 6.7154e-01, 0.0000e+00],
        [4.9528e-01, 5.0472e-01, 0.0000e+00],
        [4.0196e-01, 5.9804e-01, 0.0000e+00],
        [4.9779e-01, 5.0221e-01, 0.0000e+00],
        [3.0175e-01, 6.9825e-01, 0.0000e+00],
        [2.0079e-01, 7.9921e-01, 0.0000e+00],
        [4.8716e-01, 5.1284e-01, 0.0000e+00],
        [4.8749e-01, 5.1251e-01, 0.0000e+00],
        [4.3501e-01, 5.6499e-01, 0.0000e+00],
        [1.6744e-01, 8.3256e-01, 0.0000e+00],
        [6.9838e-02, 9.3016e-01, 0.0000e+00],
        [3.9928e-02, 9.6007e-01, 0.0000e+00]])
(info) test: tn=176,fp=31/tp=0,fn=1
(info) ROC-AUC: 0.48309178743961356
(info) PRC-AUC: 0.004629629629629629
(info) Processing "data/fold_8"...
(debug) in preprocessing...
(debug) batch_per_epoch=27
(debug) [0] train:    loss=49.62867526213328,min=1e+99
(debug) [0] validate: tn=199,fp=0/tp=0,fn=3. roc=0.8659966499162479,prc=0.36545531947830795,fβ=0.0
(debug) [0] watcher: maximal=(0.8659966499162479, 0.36545531947830795),count=1
(debug) [0] epoch time=7.747s
(debug) checkpoint saved.
(debug) [1] train:    loss=0.6952292764628375,min=49.62867526213328
(debug) [1] validate: tn=192,fp=7/tp=1,fn=2. roc=0.8877721943048577,prc=0.3870849505712159,fβ=0.18181818181818182
(debug) [1] watcher: maximal=(0.8877721943048577, 0.3870849505712159),count=2
(debug) [1] epoch time=7.224s
(debug) checkpoint saved.
(debug) [2] train:    loss=0.6718136866887411,min=0.6952292764628375
(debug) [2] validate: tn=131,fp=68/tp=3,fn=0. roc=0.8894472361809045,prc=0.3904843289705943,fβ=0.08108108108108109
(debug) [2] watcher: maximal=(0.8894472361809045, 0.3904843289705943),count=3
(debug) [2] epoch time=7.407s
(debug) checkpoint saved.
(debug) [3] train:    loss=0.6637627592793217,min=0.6718136866887411
(debug) [3] validate: tn=146,fp=53/tp=2,fn=1. roc=0.8810720268006701,prc=0.082271673174577,fβ=0.06896551724137931
(debug) [3] watcher: maximal=(0.8894472361809045, 0.3904843289705943),count=3
(debug) [3] epoch time=7.554s
(debug) [4] train:    loss=0.6488999900994478,min=0.6637627592793217
(debug) [4] validate: tn=143,fp=56/tp=3,fn=0. roc=0.88107202680067,prc=0.07862554112554113,fβ=0.0967741935483871
(debug) [4] watcher: maximal=(0.8894472361809045, 0.3904843289705943),count=3
(debug) [4] epoch time=7.380s
(debug) checkpoint loaded.
(debug) in postprocessing...
(debug) tensor([[0.4661, 0.5339, 0.0000],
        [0.4625, 0.5375, 0.0000],
        [0.4847, 0.5153, 0.0000],
        [0.4901, 0.5099, 0.0000],
        [0.4993, 0.5007, 0.0000],
        [0.4983, 0.5017, 0.0000],
        [0.4936, 0.5064, 0.0000],
        [0.4983, 0.5017, 0.0000],
        [0.4991, 0.5009, 0.0000],
        [0.4934, 0.5066, 0.0000],
        [0.4955, 0.5045, 0.0000],
        [0.4912, 0.5088, 0.0000],
        [0.4990, 0.5010, 0.0000],
        [0.4167, 0.5833, 0.0000],
        [0.4593, 0.5407, 0.0000],
        [0.4804, 0.5196, 0.0000],
        [0.4922, 0.5078, 0.0000],
        [0.4374, 0.5626, 0.0000],
        [0.4539, 0.5461, 1.0000],
        [0.4584, 0.5416, 1.0000],
        [0.4610, 0.5390, 0.0000],
        [0.2517, 0.7483, 0.0000],
        [0.4529, 0.5471, 0.0000],
        [0.4962, 0.5038, 0.0000],
        [0.3762, 0.6238, 0.0000],
        [0.4609, 0.5391, 0.0000],
        [0.4587, 0.5413, 0.0000],
        [0.4597, 0.5403, 0.0000],
        [0.4901, 0.5099, 0.0000],
        [0.4947, 0.5053, 0.0000],
        [0.4507, 0.5493, 0.0000],
        [0.4887, 0.5113, 0.0000],
        [0.4928, 0.5072, 0.0000],
        [0.4939, 0.5061, 0.0000],
        [0.4672, 0.5328, 0.0000],
        [0.0876, 0.9124, 0.0000],
        [0.4821, 0.5179, 0.0000],
        [0.4871, 0.5129, 0.0000],
        [0.4654, 0.5346, 0.0000],
        [0.4674, 0.5326, 0.0000],
        [0.4724, 0.5276, 0.0000],
        [0.3583, 0.6417, 0.0000],
        [0.4176, 0.5824, 0.0000],
        [0.4479, 0.5521, 0.0000],
        [0.4682, 0.5318, 0.0000],
        [0.4706, 0.5294, 0.0000],
        [0.4618, 0.5382, 0.0000],
        [0.4967, 0.5033, 0.0000],
        [0.4694, 0.5306, 0.0000],
        [0.4708, 0.5292, 0.0000],
        [0.4693, 0.5307, 0.0000],
        [0.3777, 0.6223, 0.0000],
        [0.4698, 0.5302, 0.0000],
        [0.4790, 0.5210, 0.0000],
        [0.4740, 0.5260, 0.0000],
        [0.4336, 0.5664, 0.0000],
        [0.4277, 0.5723, 0.0000],
        [0.4665, 0.5335, 0.0000],
        [0.4708, 0.5292, 0.0000],
        [0.4465, 0.5535, 0.0000],
        [0.4544, 0.5456, 0.0000],
        [0.4587, 0.5413, 0.0000],
        [0.4445, 0.5555, 0.0000],
        [0.4764, 0.5236, 0.0000],
        [0.4709, 0.5291, 0.0000],
        [0.4962, 0.5038, 0.0000],
        [0.4797, 0.5203, 0.0000],
        [0.4953, 0.5047, 0.0000]])
(info) test: tn=131,fp=66/tp=2,fn=2
(info) ROC-AUC: 0.6611675126903552
(info) PRC-AUC: 0.04168892804727966
(info) Processing "data/fold_9"...
(debug) in preprocessing...
(debug) batch_per_epoch=27
(debug) [0] train:    loss=55.1439453429646,min=1e+99
(debug) [0] validate: tn=1,fp=195/tp=5,fn=0. roc=0.6704081632653062,prc=0.04739739846572905,fβ=0.04878048780487806
(debug) [0] watcher: maximal=(0.6704081632653062, 0.04739739846572905),count=1
(debug) [0] epoch time=7.627s
(debug) checkpoint saved.
(debug) [1] train:    loss=0.6389215411963286,min=55.1439453429646
(debug) [1] validate: tn=71,fp=125/tp=3,fn=2. roc=0.5632653061224491,prc=0.043564333853786705,fβ=0.045112781954887216
(debug) [1] watcher: maximal=(0.6704081632653062, 0.04739739846572905),count=1
(debug) [1] epoch time=7.532s
(debug) [2] train:    loss=0.5907524161868625,min=0.6389215411963286
(debug) [2] validate: tn=137,fp=59/tp=2,fn=3. roc=0.5316326530612245,prc=0.04915289282288042,fβ=0.060606060606060615
(debug) [2] watcher: maximal=(0.6704081632653062, 0.04739739846572905),count=1
(debug) [2] epoch time=7.739s
(debug) [3] train:    loss=0.558062043454912,min=0.5907524161868625
(debug) [3] validate: tn=154,fp=42/tp=2,fn=3. roc=0.5244897959183674,prc=0.05558020759964903,fβ=0.0816326530612245
(debug) [3] watcher: maximal=(0.6704081632653062, 0.04739739846572905),count=1
(debug) [3] epoch time=7.611s
(debug) [4] train:    loss=0.5115623385817917,min=0.558062043454912
(debug) [4] validate: tn=162,fp=34/tp=2,fn=3. roc=0.5214285714285716,prc=0.05761313415865714,fβ=0.09756097560975609
(debug) [4] watcher: maximal=(0.6704081632653062, 0.04739739846572905),count=1
(debug) [4] epoch time=7.696s
(debug) checkpoint loaded.
(debug) in postprocessing...
(debug) tensor([[0.4192, 0.5808, 0.0000],
        [0.4317, 0.5683, 0.0000],
        [0.4395, 0.5605, 0.0000],
        [0.4328, 0.5672, 0.0000],
        [0.4352, 0.5648, 0.0000],
        [0.4144, 0.5856, 0.0000],
        [0.4254, 0.5746, 0.0000],
        [0.4234, 0.5766, 0.0000],
        [0.4556, 0.5444, 0.0000],
        [0.4451, 0.5549, 0.0000],
        [0.4432, 0.5568, 0.0000],
        [0.4557, 0.5443, 0.0000],
        [0.4557, 0.5443, 0.0000],
        [0.4237, 0.5763, 0.0000],
        [0.4255, 0.5745, 0.0000],
        [0.4253, 0.5747, 0.0000],
        [0.3898, 0.6102, 0.0000],
        [0.4354, 0.5646, 0.0000],
        [0.4188, 0.5812, 0.0000],
        [0.4469, 0.5531, 0.0000],
        [0.4558, 0.5442, 0.0000],
        [0.4107, 0.5893, 0.0000],
        [0.4249, 0.5751, 0.0000],
        [0.4014, 0.5986, 0.0000],
        [0.4107, 0.5893, 0.0000],
        [0.4177, 0.5823, 0.0000],
        [0.3928, 0.6072, 0.0000],
        [0.4123, 0.5877, 0.0000],
        [0.4093, 0.5907, 0.0000],
        [0.4008, 0.5992, 0.0000],
        [0.4116, 0.5884, 0.0000],
        [0.3800, 0.6200, 0.0000],
        [0.3984, 0.6016, 0.0000],
        [0.4037, 0.5963, 0.0000],
        [0.4049, 0.5951, 0.0000],
        [0.4083, 0.5917, 0.0000],
        [0.4331, 0.5669, 0.0000],
        [0.3851, 0.6149, 0.0000],
        [0.3709, 0.6291, 0.0000],
        [0.4153, 0.5847, 0.0000],
        [0.4255, 0.5745, 0.0000],
        [0.4305, 0.5695, 0.0000],
        [0.4087, 0.5913, 0.0000],
        [0.4192, 0.5808, 0.0000],
        [0.4370, 0.5630, 0.0000],
        [0.4572, 0.5428, 0.0000],
        [0.4298, 0.5702, 0.0000],
        [0.4294, 0.5706, 0.0000],
        [0.4176, 0.5824, 0.0000],
        [0.4228, 0.5772, 0.0000],
        [0.3937, 0.6063, 0.0000],
        [0.4115, 0.5885, 0.0000],
        [0.3837, 0.6163, 0.0000],
        [0.4102, 0.5898, 0.0000],
        [0.3723, 0.6277, 0.0000],
        [0.3696, 0.6304, 0.0000],
        [0.3721, 0.6279, 0.0000],
        [0.3532, 0.6468, 0.0000],
        [0.3469, 0.6531, 0.0000],
        [0.3373, 0.6627, 0.0000],
        [0.3215, 0.6785, 0.0000],
        [0.4025, 0.5975, 0.0000],
        [0.4126, 0.5874, 0.0000],
        [0.4209, 0.5791, 0.0000],
        [0.3866, 0.6134, 0.0000],
        [0.4105, 0.5895, 0.0000],
        [0.4144, 0.5856, 0.0000],
        [0.4225, 0.5775, 0.0000],
        [0.4066, 0.5934, 0.0000],
        [0.4181, 0.5819, 0.0000],
        [0.4059, 0.5941, 0.0000],
        [0.4113, 0.5887, 0.0000],
        [0.4139, 0.5861, 0.0000],
        [0.4020, 0.5980, 0.0000],
        [0.4156, 0.5844, 0.0000],
        [0.4060, 0.5940, 0.0000],
        [0.4420, 0.5580, 0.0000],
        [0.4428, 0.5572, 0.0000],
        [0.4506, 0.5494, 0.0000],
        [0.3561, 0.6439, 0.0000],
        [0.3584, 0.6416, 0.0000],
        [0.3561, 0.6439, 0.0000],
        [0.4055, 0.5945, 0.0000],
        [0.3986, 0.6014, 0.0000],
        [0.4126, 0.5874, 0.0000],
        [0.3540, 0.6460, 0.0000],
        [0.3729, 0.6271, 0.0000],
        [0.4556, 0.5444, 0.0000],
        [0.4314, 0.5686, 0.0000],
        [0.3891, 0.6109, 0.0000],
        [0.3625, 0.6375, 0.0000],
        [0.4062, 0.5938, 0.0000],
        [0.3844, 0.6156, 0.0000],
        [0.3746, 0.6254, 0.0000],
        [0.3704, 0.6296, 0.0000],
        [0.4105, 0.5895, 0.0000],
        [0.4132, 0.5868, 0.0000],
        [0.3559, 0.6441, 0.0000],
        [0.3517, 0.6483, 0.0000],
        [0.3174, 0.6826, 0.0000],
        [0.3936, 0.6064, 0.0000],
        [0.4164, 0.5836, 0.0000],
        [0.4105, 0.5895, 0.0000],
        [0.4287, 0.5713, 0.0000],
        [0.4192, 0.5808, 0.0000],
        [0.3942, 0.6058, 0.0000],
        [0.4058, 0.5942, 0.0000],
        [0.4163, 0.5837, 0.0000],
        [0.4028, 0.5972, 0.0000],
        [0.3132, 0.6868, 0.0000],
        [0.2995, 0.7005, 0.0000],
        [0.3654, 0.6346, 1.0000],
        [0.3345, 0.6655, 1.0000],
        [0.3965, 0.6035, 1.0000],
        [0.3916, 0.6084, 0.0000],
        [0.3950, 0.6050, 0.0000],
        [0.3720, 0.6280, 0.0000],
        [0.4261, 0.5739, 0.0000],
        [0.4261, 0.5739, 0.0000],
        [0.3761, 0.6239, 0.0000],
        [0.4502, 0.5498, 0.0000],
        [0.3958, 0.6042, 0.0000],
        [0.3705, 0.6295, 0.0000],
        [0.4319, 0.5681, 0.0000],
        [0.4014, 0.5986, 0.0000],
        [0.4521, 0.5479, 0.0000],
        [0.3841, 0.6159, 0.0000],
        [0.4194, 0.5806, 0.0000],
        [0.4398, 0.5602, 0.0000],
        [0.3799, 0.6201, 0.0000],
        [0.4284, 0.5716, 0.0000],
        [0.4381, 0.5619, 0.0000],
        [0.3775, 0.6225, 0.0000],
        [0.3472, 0.6528, 0.0000],
        [0.3731, 0.6269, 0.0000],
        [0.3864, 0.6136, 0.0000],
        [0.4214, 0.5786, 0.0000],
        [0.3562, 0.6438, 0.0000],
        [0.4532, 0.5468, 0.0000],
        [0.3697, 0.6303, 0.0000],
        [0.4368, 0.5632, 0.0000],
        [0.3532, 0.6468, 0.0000],
        [0.4367, 0.5633, 0.0000],
        [0.4041, 0.5959, 0.0000],
        [0.3845, 0.6155, 0.0000],
        [0.4015, 0.5985, 0.0000],
        [0.4755, 0.5245, 0.0000],
        [0.3882, 0.6118, 0.0000],
        [0.4217, 0.5783, 0.0000],
        [0.4131, 0.5869, 0.0000],
        [0.3299, 0.6701, 0.0000],
        [0.3775, 0.6225, 0.0000],
        [0.4372, 0.5628, 0.0000],
        [0.3767, 0.6233, 0.0000],
        [0.3720, 0.6280, 0.0000],
        [0.3822, 0.6178, 0.0000],
        [0.3496, 0.6504, 0.0000],
        [0.4393, 0.5607, 0.0000],
        [0.4261, 0.5739, 0.0000],
        [0.4180, 0.5820, 0.0000],
        [0.3663, 0.6337, 0.0000],
        [0.3172, 0.6828, 0.0000],
        [0.3802, 0.6198, 0.0000],
        [0.4171, 0.5829, 0.0000],
        [0.4086, 0.5914, 0.0000],
        [0.3775, 0.6225, 0.0000],
        [0.4309, 0.5691, 0.0000],
        [0.3716, 0.6284, 0.0000],
        [0.3768, 0.6232, 0.0000],
        [0.4087, 0.5913, 0.0000],
        [0.4405, 0.5595, 0.0000],
        [0.4091, 0.5909, 0.0000],
        [0.3931, 0.6069, 0.0000],
        [0.3852, 0.6148, 0.0000],
        [0.4073, 0.5927, 0.0000],
        [0.3541, 0.6459, 0.0000],
        [0.4170, 0.5830, 0.0000],
        [0.4136, 0.5864, 0.0000],
        [0.3675, 0.6325, 0.0000],
        [0.4143, 0.5857, 0.0000],
        [0.4207, 0.5793, 0.0000],
        [0.3714, 0.6286, 0.0000],
        [0.3931, 0.6069, 0.0000],
        [0.3877, 0.6123, 0.0000],
        [0.3815, 0.6185, 0.0000],
        [0.3406, 0.6594, 0.0000],
        [0.4514, 0.5486, 0.0000],
        [0.3910, 0.6090, 0.0000],
        [0.4408, 0.5592, 0.0000],
        [0.4528, 0.5472, 0.0000],
        [0.4553, 0.5447, 0.0000],
        [0.4266, 0.5735, 0.0000],
        [0.4264, 0.5736, 0.0000],
        [0.4261, 0.5739, 0.0000],
        [0.4149, 0.5851, 0.0000],
        [0.4232, 0.5768, 0.0000],
        [0.3796, 0.6204, 0.0000],
        [0.4385, 0.5615, 0.0000],
        [0.4072, 0.5928, 0.0000],
        [0.3955, 0.6045, 0.0000],
        [0.3699, 0.6301, 0.0000],
        [0.4542, 0.5458, 0.0000]])
(info) test: tn=0,fp=199/tp=3,fn=0
(info) ROC-AUC: 0.829145728643216
(info) PRC-AUC: 0.055824260915794094
(info) roc = [0.7041, 0.894, 0.8084, 0.6578, 0.859, 0.537, 0.7746, 0.4831, 0.6612, 0.8291]
(info) prc = [0.0678, 0.2436, 0.1007, 0.0291, 0.1179, 0.0147, 0.0477, 0.0046, 0.0417, 0.0558]
(info) All folds: ROC-AUC = 0.721±0.137, PRC-AUC = 0.072±0.070
