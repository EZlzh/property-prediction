(info) Number of threads: 16
(info) Preparing data...
(debug) no cache loaded.
(debug) Ignored "data/train.csv".
(info) Processing "data/fold_0"...
(debug) in preprocessing...
(debug) batch_per_epoch=27
(debug) [0] train:    loss=0.7115526066886054,min=1e+99
(debug) [0] validate: tn=144,fp=44/tp=10,fn=4. roc=0.8081306990881459,prc=0.16134084875186233,fβ=0.2941176470588235
(debug) [0] watcher: maximal=(0.8081306990881459, 0.16134084875186233),count=1
(debug) [0] epoch time=8.826s
(debug) checkpoint saved.
(debug) [1] train:    loss=0.5906240752449742,min=0.7115526066886054
(debug) [1] validate: tn=122,fp=66/tp=9,fn=5. roc=0.75,prc=0.14678730300642137,fβ=0.20224719101123598
(debug) [1] watcher: maximal=(0.8081306990881459, 0.16134084875186233),count=1
(debug) [1] epoch time=8.588s
(debug) [2] train:    loss=0.5054435454033039,min=0.5906240752449742
(debug) [2] validate: tn=148,fp=40/tp=10,fn=4. roc=0.8252279635258359,prc=0.23761476908959442,fβ=0.3125
(debug) [2] watcher: maximal=(0.8252279635258359, 0.23761476908959442),count=2
(debug) [2] epoch time=8.674s
(debug) checkpoint saved.
(debug) [3] train:    loss=0.44728743809240834,min=0.5054435454033039
(debug) [3] validate: tn=161,fp=27/tp=10,fn=4. roc=0.8541033434650456,prc=0.29570625862368993,fβ=0.39215686274509803
(debug) [3] watcher: maximal=(0.8541033434650456, 0.29570625862368993),count=3
(debug) [3] epoch time=8.676s
(debug) checkpoint saved.
(debug) [4] train:    loss=0.3908016687190091,min=0.44728743809240834
(debug) [4] validate: tn=149,fp=39/tp=13,fn=1. roc=0.8628419452887538,prc=0.47498553070603644,fβ=0.3939393939393939
(debug) [4] watcher: maximal=(0.8628419452887538, 0.47498553070603644),count=4
(debug) [4] epoch time=8.696s
(debug) checkpoint saved.
(debug) checkpoint loaded.
(debug) in postprocessing...
(debug) tensor([[0.1530, 0.8470, 0.0000],
        [0.1934, 0.8066, 0.0000],
        [0.0757, 0.9243, 0.0000],
        [0.1292, 0.8708, 0.0000],
        [0.1383, 0.8617, 0.0000],
        [0.3346, 0.6654, 0.0000],
        [0.0977, 0.9023, 0.0000],
        [0.2060, 0.7940, 0.0000],
        [0.0828, 0.9172, 0.0000],
        [0.2052, 0.7948, 0.0000],
        [0.1059, 0.8942, 0.0000],
        [0.4357, 0.5643, 0.0000],
        [0.4961, 0.5039, 0.0000],
        [0.0802, 0.9198, 0.0000],
        [0.0753, 0.9247, 0.0000],
        [0.0963, 0.9037, 1.0000],
        [0.0512, 0.9488, 1.0000],
        [0.3764, 0.6236, 0.0000],
        [0.1825, 0.8175, 0.0000],
        [0.1903, 0.8097, 0.0000],
        [0.2648, 0.7352, 0.0000],
        [0.1712, 0.8288, 0.0000],
        [0.2535, 0.7465, 0.0000],
        [0.4153, 0.5847, 0.0000],
        [0.2788, 0.7212, 0.0000],
        [0.1477, 0.8523, 0.0000],
        [0.3069, 0.6931, 0.0000],
        [0.0701, 0.9299, 0.0000],
        [0.0944, 0.9056, 0.0000],
        [0.0654, 0.9346, 0.0000],
        [0.2572, 0.7428, 0.0000],
        [0.0451, 0.9549, 0.0000],
        [0.0829, 0.9171, 0.0000],
        [0.0781, 0.9219, 0.0000],
        [0.0448, 0.9552, 0.0000],
        [0.0592, 0.9408, 0.0000],
        [0.3085, 0.6915, 0.0000],
        [0.2315, 0.7685, 0.0000],
        [0.0433, 0.9567, 0.0000]])
(info) test: tn=159,fp=37/tp=2,fn=3
(info) ROC-AUC: 0.6602040816326531
(info) PRC-AUC: 0.06457085539188581
(info) Processing "data/fold_1"...
(debug) in preprocessing...
(debug) batch_per_epoch=27
(debug) [0] train:    loss=0.7501316909436826,min=1e+99
(debug) [0] validate: tn=178,fp=19/tp=2,fn=2. roc=0.7956852791878173,prc=0.30058306284381897,fβ=0.16
(debug) [0] watcher: maximal=(0.7956852791878173, 0.30058306284381897),count=1
(debug) [0] epoch time=8.814s
(debug) checkpoint saved.
(debug) [1] train:    loss=0.6620828619709721,min=0.7501316909436826
(debug) [1] validate: tn=112,fp=85/tp=3,fn=1. roc=0.7690355329949239,prc=0.05309065039670573,fβ=0.06521739130434782
(debug) [1] watcher: maximal=(0.7956852791878173, 0.30058306284381897),count=1
(debug) [1] epoch time=8.644s
(debug) [2] train:    loss=0.5925724594681351,min=0.6620828619709721
(debug) [2] validate: tn=137,fp=60/tp=3,fn=1. roc=0.8489847715736041,prc=0.3312924575424575,fβ=0.08955223880597014
(debug) [2] watcher: maximal=(0.8489847715736041, 0.3312924575424575),count=2
(debug) [2] epoch time=9.109s
(debug) checkpoint saved.
(debug) [3] train:    loss=0.5246397775632364,min=0.5925724594681351
(debug) [3] validate: tn=175,fp=22/tp=3,fn=1. roc=0.8096446700507614,prc=0.1618204099821747,fβ=0.20689655172413793
(debug) [3] watcher: maximal=(0.8489847715736041, 0.3312924575424575),count=2
(debug) [3] epoch time=9.254s
(debug) [4] train:    loss=0.466331923449481,min=0.5246397775632364
(debug) [4] validate: tn=179,fp=18/tp=3,fn=1. roc=0.7982233502538071,prc=0.1397961293974225,fβ=0.24
(debug) [4] watcher: maximal=(0.8489847715736041, 0.3312924575424575),count=2
(debug) [4] epoch time=9.291s
(debug) checkpoint loaded.
(debug) in postprocessing...
(debug) tensor([[0.4806, 0.5194, 0.0000],
        [0.3488, 0.6512, 0.0000],
        [0.2438, 0.7562, 0.0000],
        [0.4571, 0.5429, 0.0000],
        [0.2592, 0.7408, 0.0000],
        [0.1886, 0.8114, 0.0000],
        [0.4955, 0.5045, 0.0000],
        [0.1722, 0.8278, 0.0000],
        [0.4102, 0.5898, 0.0000],
        [0.1828, 0.8172, 0.0000],
        [0.1615, 0.8385, 0.0000],
        [0.3584, 0.6416, 0.0000],
        [0.1278, 0.8722, 0.0000],
        [0.3588, 0.6412, 1.0000],
        [0.1894, 0.8106, 1.0000],
        [0.4563, 0.5437, 1.0000],
        [0.1942, 0.8058, 1.0000],
        [0.4619, 0.5381, 1.0000],
        [0.1962, 0.8038, 1.0000],
        [0.2261, 0.7739, 0.0000],
        [0.1238, 0.8762, 1.0000],
        [0.1225, 0.8775, 1.0000],
        [0.1225, 0.8775, 1.0000],
        [0.1160, 0.8840, 1.0000],
        [0.1170, 0.8830, 1.0000],
        [0.4985, 0.5015, 0.0000],
        [0.4763, 0.5237, 0.0000],
        [0.1612, 0.8388, 0.0000],
        [0.2942, 0.7058, 0.0000],
        [0.1328, 0.8672, 0.0000],
        [0.2942, 0.7058, 0.0000],
        [0.1347, 0.8653, 0.0000],
        [0.1154, 0.8846, 0.0000],
        [0.1216, 0.8784, 0.0000],
        [0.3380, 0.6620, 0.0000],
        [0.1904, 0.8096, 0.0000],
        [0.3984, 0.6016, 0.0000],
        [0.2309, 0.7691, 0.0000],
        [0.2101, 0.7899, 0.0000],
        [0.4594, 0.5406, 0.0000],
        [0.2333, 0.7667, 0.0000],
        [0.2442, 0.7558, 0.0000],
        [0.4558, 0.5442, 0.0000],
        [0.2126, 0.7874, 0.0000],
        [0.1174, 0.8826, 0.0000],
        [0.3176, 0.6824, 0.0000],
        [0.1211, 0.8789, 0.0000],
        [0.1263, 0.8737, 0.0000],
        [0.1868, 0.8132, 0.0000],
        [0.1272, 0.8728, 0.0000],
        [0.4689, 0.5311, 0.0000],
        [0.3450, 0.6550, 0.0000],
        [0.1162, 0.8838, 1.0000],
        [0.1193, 0.8807, 0.0000],
        [0.3961, 0.6039, 0.0000],
        [0.3197, 0.6803, 0.0000],
        [0.4832, 0.5168, 0.0000],
        [0.1437, 0.8563, 0.0000],
        [0.1239, 0.8761, 0.0000],
        [0.1928, 0.8072, 0.0000],
        [0.2476, 0.7524, 0.0000],
        [0.3559, 0.6441, 0.0000],
        [0.1603, 0.8397, 0.0000],
        [0.1883, 0.8117, 0.0000],
        [0.1253, 0.8747, 0.0000],
        [0.2654, 0.7346, 0.0000],
        [0.2527, 0.7473, 0.0000],
        [0.1502, 0.8498, 0.0000],
        [0.1542, 0.8458, 0.0000],
        [0.2426, 0.7574, 0.0000],
        [0.1351, 0.8649, 0.0000],
        [0.1163, 0.8837, 0.0000],
        [0.1292, 0.8708, 0.0000],
        [0.1321, 0.8679, 0.0000],
        [0.1372, 0.8628, 0.0000],
        [0.1135, 0.8865, 0.0000],
        [0.1349, 0.8651, 0.0000],
        [0.1173, 0.8827, 0.0000]])
(info) test: tn=122,fp=66/tp=12,fn=2
(info) ROC-AUC: 0.7933130699088146
(info) PRC-AUC: 0.23827044667074074
(info) Processing "data/fold_2"...
(debug) in preprocessing...
(debug) batch_per_epoch=27
(debug) [0] train:    loss=0.7684156055803653,min=1e+99
(debug) [0] validate: tn=0,fp=198/tp=4,fn=0. roc=0.2916666666666667,prc=0.013728601286905034,fβ=0.038834951456310676
(debug) [0] watcher: maximal=(0.2916666666666667, 0.013728601286905034),count=1
(debug) [0] epoch time=9.148s
(debug) checkpoint saved.
(debug) [1] train:    loss=0.7081727032308225,min=0.7684156055803653
(debug) [1] validate: tn=43,fp=155/tp=4,fn=0. roc=0.7058080808080808,prc=0.0484738260507965,fβ=0.049079754601226995
(debug) [1] watcher: maximal=(0.7058080808080808, 0.0484738260507965),count=2
(debug) [1] epoch time=9.351s
(debug) checkpoint saved.
(debug) [2] train:    loss=0.6037308816556577,min=0.7081727032308225
(debug) [2] validate: tn=149,fp=49/tp=2,fn=2. roc=0.6477272727272727,prc=0.03145518151262849,fβ=0.07272727272727272
(debug) [2] watcher: maximal=(0.7058080808080808, 0.0484738260507965),count=2
(debug) [2] epoch time=9.052s
(debug) [3] train:    loss=0.516263378991021,min=0.6037308816556577
(debug) [3] validate: tn=113,fp=85/tp=2,fn=2. roc=0.547979797979798,prc=0.027159852876021982,fβ=0.04395604395604396
(debug) [3] watcher: maximal=(0.7058080808080808, 0.0484738260507965),count=2
(debug) [3] epoch time=9.062s
(debug) [4] train:    loss=0.4578662536762379,min=0.516263378991021
(debug) [4] validate: tn=179,fp=19/tp=1,fn=3. roc=0.48484848484848486,prc=0.031204645463296467,fβ=0.08333333333333334
(debug) [4] watcher: maximal=(0.7058080808080808, 0.0484738260507965),count=2
(debug) [4] epoch time=9.082s
(debug) checkpoint loaded.
(debug) in postprocessing...
(debug) tensor([[0.4421, 0.5579, 0.0000],
        [0.4882, 0.5118, 0.0000],
        [0.4584, 0.5416, 0.0000],
        [0.4676, 0.5324, 0.0000],
        [0.4619, 0.5381, 0.0000],
        [0.4582, 0.5418, 0.0000],
        [0.4943, 0.5057, 0.0000],
        [0.4540, 0.5460, 0.0000],
        [0.4776, 0.5224, 0.0000],
        [0.4725, 0.5275, 0.0000],
        [0.4479, 0.5521, 0.0000],
        [0.4638, 0.5362, 0.0000],
        [0.4637, 0.5363, 0.0000],
        [0.4770, 0.5230, 0.0000],
        [0.4819, 0.5181, 0.0000],
        [0.4621, 0.5379, 0.0000],
        [0.4746, 0.5254, 0.0000],
        [0.4819, 0.5181, 0.0000],
        [0.4557, 0.5443, 0.0000],
        [0.4588, 0.5412, 0.0000],
        [0.4728, 0.5272, 0.0000],
        [0.4894, 0.5106, 0.0000],
        [0.4913, 0.5087, 0.0000],
        [0.4633, 0.5367, 0.0000],
        [0.4447, 0.5553, 0.0000],
        [0.4861, 0.5139, 0.0000],
        [0.4414, 0.5586, 0.0000],
        [0.4143, 0.5857, 0.0000],
        [0.4115, 0.5885, 0.0000],
        [0.4339, 0.5661, 0.0000],
        [0.4100, 0.5900, 0.0000],
        [0.4906, 0.5094, 0.0000],
        [0.4569, 0.5431, 1.0000],
        [0.4751, 0.5249, 0.0000],
        [0.4560, 0.5440, 0.0000],
        [0.4792, 0.5208, 0.0000],
        [0.4489, 0.5511, 0.0000],
        [0.4566, 0.5434, 0.0000],
        [0.4329, 0.5671, 0.0000],
        [0.4705, 0.5295, 0.0000],
        [0.4774, 0.5226, 0.0000],
        [0.4864, 0.5136, 0.0000],
        [0.4937, 0.5063, 0.0000],
        [0.4558, 0.5442, 0.0000],
        [0.4607, 0.5393, 0.0000],
        [0.4730, 0.5270, 0.0000],
        [0.4758, 0.5242, 0.0000],
        [0.4908, 0.5092, 0.0000],
        [0.4356, 0.5644, 0.0000],
        [0.4277, 0.5723, 0.0000],
        [0.4719, 0.5281, 0.0000],
        [0.4599, 0.5401, 0.0000],
        [0.4599, 0.5401, 0.0000],
        [0.4608, 0.5392, 0.0000],
        [0.4885, 0.5115, 0.0000],
        [0.4687, 0.5313, 0.0000],
        [0.4849, 0.5151, 0.0000],
        [0.4904, 0.5096, 0.0000],
        [0.4882, 0.5118, 0.0000],
        [0.4751, 0.5249, 0.0000],
        [0.4539, 0.5461, 0.0000],
        [0.4703, 0.5297, 0.0000],
        [0.4723, 0.5277, 0.0000],
        [0.4818, 0.5182, 0.0000],
        [0.4616, 0.5384, 0.0000],
        [0.4789, 0.5211, 0.0000],
        [0.4632, 0.5368, 0.0000],
        [0.4672, 0.5328, 0.0000],
        [0.4756, 0.5244, 0.0000],
        [0.4586, 0.5414, 0.0000],
        [0.4532, 0.5468, 0.0000],
        [0.4571, 0.5429, 0.0000],
        [0.4460, 0.5540, 0.0000],
        [0.4746, 0.5254, 0.0000],
        [0.4669, 0.5331, 0.0000],
        [0.4375, 0.5625, 1.0000],
        [0.4356, 0.5644, 1.0000],
        [0.4149, 0.5851, 1.0000],
        [0.4867, 0.5133, 0.0000],
        [0.4508, 0.5492, 0.0000],
        [0.4660, 0.5340, 0.0000],
        [0.4774, 0.5226, 0.0000],
        [0.4740, 0.5260, 0.0000],
        [0.4405, 0.5595, 0.0000],
        [0.4604, 0.5396, 0.0000],
        [0.4322, 0.5678, 0.0000],
        [0.4720, 0.5280, 0.0000],
        [0.4495, 0.5505, 0.0000],
        [0.4960, 0.5040, 0.0000],
        [0.4753, 0.5247, 0.0000],
        [0.4948, 0.5052, 0.0000],
        [0.4417, 0.5583, 0.0000],
        [0.4803, 0.5197, 0.0000],
        [0.4689, 0.5311, 0.0000],
        [0.4317, 0.5683, 0.0000],
        [0.4667, 0.5333, 0.0000],
        [0.4516, 0.5484, 0.0000],
        [0.4974, 0.5026, 0.0000],
        [0.4722, 0.5278, 0.0000],
        [0.4527, 0.5473, 0.0000],
        [0.4991, 0.5009, 0.0000],
        [0.4824, 0.5176, 0.0000],
        [0.4667, 0.5333, 0.0000],
        [0.4708, 0.5292, 0.0000],
        [0.4808, 0.5192, 0.0000],
        [0.4746, 0.5254, 0.0000],
        [0.4797, 0.5203, 0.0000],
        [0.4953, 0.5047, 0.0000],
        [0.4550, 0.5450, 0.0000],
        [0.4699, 0.5301, 0.0000],
        [0.4614, 0.5386, 0.0000],
        [0.4962, 0.5038, 0.0000],
        [0.4758, 0.5242, 0.0000],
        [0.4911, 0.5089, 0.0000],
        [0.4845, 0.5155, 0.0000],
        [0.4525, 0.5475, 0.0000],
        [0.4668, 0.5332, 0.0000],
        [0.4774, 0.5226, 0.0000],
        [0.4940, 0.5060, 0.0000],
        [0.4857, 0.5143, 0.0000],
        [0.4918, 0.5082, 0.0000],
        [0.4816, 0.5184, 0.0000],
        [0.4478, 0.5522, 0.0000],
        [0.4830, 0.5170, 0.0000],
        [0.4757, 0.5243, 0.0000],
        [0.4776, 0.5224, 0.0000],
        [0.4362, 0.5638, 0.0000],
        [0.4190, 0.5810, 0.0000],
        [0.4431, 0.5569, 0.0000],
        [0.4749, 0.5251, 0.0000],
        [0.4860, 0.5140, 0.0000],
        [0.4844, 0.5156, 0.0000],
        [0.4659, 0.5341, 0.0000],
        [0.4774, 0.5226, 0.0000],
        [0.4421, 0.5579, 0.0000],
        [0.4832, 0.5168, 0.0000],
        [0.4878, 0.5122, 0.0000],
        [0.4875, 0.5125, 0.0000],
        [0.4285, 0.5715, 0.0000],
        [0.4729, 0.5271, 0.0000],
        [0.4899, 0.5101, 0.0000],
        [0.4848, 0.5152, 0.0000],
        [0.4848, 0.5152, 0.0000],
        [0.4769, 0.5231, 0.0000],
        [0.4689, 0.5311, 0.0000],
        [0.4461, 0.5539, 0.0000],
        [0.4413, 0.5587, 0.0000]])
(info) test: tn=54,fp=143/tp=4,fn=0
(info) ROC-AUC: 0.9200507614213198
(info) PRC-AUC: 0.1273552159222891
(info) Processing "data/fold_3"...
(debug) in preprocessing...
(debug) batch_per_epoch=27
(debug) [0] train:    loss=0.7323405058295639,min=1e+99
(debug) [0] validate: tn=24,fp=171/tp=6,fn=0. roc=0.8094017094017094,prc=0.07898617325237259,fβ=0.06557377049180328
(debug) [0] watcher: maximal=(0.8094017094017094, 0.07898617325237259),count=1
(debug) [0] epoch time=9.455s
(debug) checkpoint saved.
(debug) [1] train:    loss=0.6739889118406508,min=0.7323405058295639
(debug) [1] validate: tn=69,fp=126/tp=6,fn=0. roc=0.8307692307692308,prc=0.12169303445853534,fβ=0.08695652173913045
(debug) [1] watcher: maximal=(0.8307692307692308, 0.12169303445853534),count=2
(debug) [1] epoch time=8.914s
(debug) checkpoint saved.
(debug) [2] train:    loss=0.529820062496044,min=0.6739889118406508
(debug) [2] validate: tn=158,fp=37/tp=4,fn=2. roc=0.8735042735042735,prc=0.2900238729209047,fβ=0.1702127659574468
(debug) [2] watcher: maximal=(0.8735042735042735, 0.2900238729209047),count=3
(debug) [2] epoch time=9.142s
(debug) checkpoint saved.
(debug) [3] train:    loss=0.4868217651490812,min=0.529820062496044
(debug) [3] validate: tn=171,fp=24/tp=4,fn=2. roc=0.9025641025641025,prc=0.30742810318600494,fβ=0.23529411764705882
(debug) [3] watcher: maximal=(0.9025641025641025, 0.30742810318600494),count=4
(debug) [3] epoch time=9.169s
(debug) checkpoint saved.
(debug) [4] train:    loss=0.46235565344492596,min=0.4868217651490812
(debug) [4] validate: tn=162,fp=33/tp=4,fn=2. roc=0.9076923076923078,prc=0.35557388967715053,fβ=0.18604651162790697
(debug) [4] watcher: maximal=(0.9076923076923078, 0.35557388967715053),count=5
(debug) [4] epoch time=9.192s
(debug) checkpoint saved.
(debug) checkpoint loaded.
(debug) in postprocessing...
(debug) tensor([[0.4823, 0.5177, 0.0000],
        [0.4823, 0.5177, 0.0000],
        [0.3308, 0.6692, 0.0000],
        [0.3437, 0.6563, 0.0000],
        [0.2291, 0.7709, 0.0000],
        [0.4060, 0.5940, 0.0000],
        [0.3457, 0.6543, 0.0000],
        [0.0357, 0.9643, 0.0000],
        [0.0426, 0.9574, 0.0000],
        [0.1145, 0.8855, 0.0000],
        [0.4812, 0.5188, 0.0000],
        [0.1751, 0.8249, 0.0000],
        [0.0503, 0.9497, 0.0000],
        [0.4091, 0.5909, 0.0000],
        [0.2123, 0.7877, 0.0000],
        [0.4385, 0.5615, 0.0000],
        [0.4275, 0.5725, 1.0000],
        [0.0357, 0.9643, 1.0000],
        [0.1556, 0.8444, 0.0000],
        [0.1050, 0.8950, 0.0000],
        [0.0566, 0.9434, 0.0000],
        [0.3590, 0.6410, 0.0000],
        [0.0391, 0.9609, 0.0000],
        [0.4652, 0.5348, 0.0000],
        [0.4921, 0.5079, 0.0000],
        [0.1148, 0.8852, 0.0000],
        [0.1833, 0.8167, 0.0000]])
(info) test: tn=173,fp=25/tp=2,fn=2
(info) ROC-AUC: 0.667929292929293
(info) PRC-AUC: 0.28012467412855846
(info) Processing "data/fold_4"...
(debug) in preprocessing...
(debug) batch_per_epoch=27
(debug) [0] train:    loss=0.743175709689105,min=1e+99
(debug) [0] validate: tn=196,fp=2/tp=0,fn=3. roc=0.9461279461279463,prc=0.11479767795557269,fβ=0.0
(debug) [0] watcher: maximal=(0.9461279461279463, 0.11479767795557269),count=1
(debug) [0] epoch time=9.311s
(debug) checkpoint saved.
(debug) [1] train:    loss=0.6605277326371934,min=0.743175709689105
(debug) [1] validate: tn=149,fp=49/tp=3,fn=0. roc=0.9410774410774411,prc=0.13386428386428387,fβ=0.1090909090909091
(debug) [1] watcher: maximal=(0.9461279461279463, 0.11479767795557269),count=1
(debug) [1] epoch time=9.135s
(debug) [2] train:    loss=0.5554263304781031,min=0.6605277326371934
(debug) [2] validate: tn=156,fp=42/tp=3,fn=0. roc=0.9663299663299663,prc=0.19468954248366013,fβ=0.125
(debug) [2] watcher: maximal=(0.9663299663299663, 0.19468954248366013),count=2
(debug) [2] epoch time=9.408s
(debug) checkpoint saved.
(debug) [3] train:    loss=0.4977212404763257,min=0.5554263304781031
(debug) [3] validate: tn=158,fp=40/tp=3,fn=0. roc=0.9595959595959596,prc=0.19047619047619047,fβ=0.13043478260869565
(debug) [3] watcher: maximal=(0.9663299663299663, 0.19468954248366013),count=2
(debug) [3] epoch time=9.221s
(debug) [4] train:    loss=0.4464934666951497,min=0.4977212404763257
(debug) [4] validate: tn=165,fp=33/tp=3,fn=0. roc=0.9225589225589226,prc=0.108008658008658,fβ=0.15384615384615385
(debug) [4] watcher: maximal=(0.9663299663299663, 0.19468954248366013),count=2
(debug) [4] epoch time=9.035s
(debug) checkpoint loaded.
(debug) in postprocessing...
(debug) tensor([[0.4219, 0.5781, 0.0000],
        [0.3562, 0.6438, 0.0000],
        [0.1225, 0.8775, 0.0000],
        [0.1736, 0.8264, 0.0000],
        [0.1213, 0.8787, 0.0000],
        [0.1670, 0.8330, 0.0000],
        [0.1514, 0.8486, 0.0000],
        [0.4471, 0.5529, 0.0000],
        [0.2217, 0.7783, 0.0000],
        [0.1476, 0.8524, 0.0000],
        [0.1212, 0.8788, 1.0000],
        [0.3886, 0.6114, 1.0000],
        [0.2442, 0.7558, 1.0000],
        [0.1242, 0.8758, 1.0000],
        [0.1452, 0.8548, 0.0000],
        [0.1215, 0.8785, 0.0000],
        [0.3502, 0.6498, 0.0000],
        [0.3024, 0.6976, 0.0000],
        [0.2671, 0.7329, 0.0000],
        [0.2967, 0.7033, 0.0000],
        [0.4022, 0.5978, 0.0000],
        [0.4517, 0.5483, 0.0000],
        [0.3571, 0.6429, 0.0000],
        [0.4152, 0.5848, 0.0000],
        [0.3288, 0.6712, 0.0000],
        [0.2258, 0.7742, 0.0000],
        [0.3750, 0.6250, 0.0000],
        [0.1255, 0.8745, 0.0000],
        [0.2161, 0.7839, 0.0000],
        [0.1630, 0.8370, 0.0000],
        [0.4979, 0.5021, 0.0000],
        [0.1266, 0.8734, 0.0000],
        [0.3564, 0.6436, 0.0000],
        [0.4163, 0.5837, 0.0000],
        [0.4162, 0.5838, 0.0000],
        [0.4353, 0.5647, 0.0000],
        [0.1331, 0.8669, 0.0000],
        [0.3697, 0.6303, 0.0000],
        [0.4957, 0.5043, 0.0000],
        [0.4514, 0.5486, 0.0000],
        [0.1237, 0.8763, 0.0000],
        [0.4445, 0.5555, 0.0000],
        [0.4649, 0.5351, 0.0000]])
(info) test: tn=156,fp=39/tp=4,fn=2
(info) ROC-AUC: 0.8641025641025641
(info) PRC-AUC: 0.2817660769744438
(info) Processing "data/fold_5"...
(debug) in preprocessing...
(debug) batch_per_epoch=26
(debug) [0] train:    loss=0.7349451711544623,min=1e+99
(debug) [0] validate: tn=111,fp=163/tp=3,fn=1. roc=0.36952554744525545,prc=0.010677334687745139,fβ=0.03529411764705882
(debug) [0] watcher: maximal=(0.36952554744525545, 0.010677334687745139),count=1
(debug) [0] epoch time=9.119s
(debug) checkpoint saved.
(debug) [1] train:    loss=0.6438155690064797,min=0.7349451711544623
(debug) [1] validate: tn=251,fp=23/tp=0,fn=4. roc=0.3494525547445256,prc=0.010294944242972944,fβ=0.0
(debug) [1] watcher: maximal=(0.36952554744525545, 0.010677334687745139),count=1
(debug) [1] epoch time=8.900s
(debug) [2] train:    loss=0.5242296262429311,min=0.6438155690064797
(debug) [2] validate: tn=229,fp=45/tp=0,fn=4. roc=0.4023722627737226,prc=0.011195377830046887,fβ=0.0
(debug) [2] watcher: maximal=(0.4023722627737226, 0.011195377830046887),count=2
(debug) [2] epoch time=8.959s
(debug) checkpoint saved.
(debug) [3] train:    loss=0.453848945406767,min=0.5242296262429311
(debug) [3] validate: tn=238,fp=36/tp=0,fn=4. roc=0.31934306569343063,prc=0.00966608841384857,fβ=0.0
(debug) [3] watcher: maximal=(0.4023722627737226, 0.011195377830046887),count=2
(debug) [3] epoch time=8.942s
(debug) [4] train:    loss=0.394863811823038,min=0.453848945406767
(debug) [4] validate: tn=265,fp=9/tp=0,fn=4. roc=0.3147810218978102,prc=0.009709474123653677,fβ=0.0
(debug) [4] watcher: maximal=(0.4023722627737226, 0.011195377830046887),count=2
(debug) [4] epoch time=8.679s
(debug) checkpoint loaded.
(debug) in postprocessing...
(debug) tensor([[0.4404, 0.5596, 0.0000],
        [0.4359, 0.5641, 0.0000],
        [0.0725, 0.9275, 0.0000],
        [0.3791, 0.6209, 0.0000],
        [0.1866, 0.8134, 0.0000],
        [0.1627, 0.8373, 0.0000],
        [0.0841, 0.9159, 0.0000],
        [0.3966, 0.6034, 0.0000],
        [0.2887, 0.7113, 0.0000],
        [0.4308, 0.5692, 0.0000],
        [0.1019, 0.8981, 0.0000],
        [0.2256, 0.7744, 0.0000],
        [0.3045, 0.6955, 0.0000],
        [0.0943, 0.9057, 1.0000],
        [0.0857, 0.9143, 0.0000],
        [0.4193, 0.5807, 0.0000],
        [0.4184, 0.5816, 0.0000],
        [0.0812, 0.9188, 0.0000],
        [0.3842, 0.6158, 0.0000],
        [0.1069, 0.8931, 0.0000],
        [0.0807, 0.9193, 0.0000],
        [0.4667, 0.5333, 0.0000],
        [0.4482, 0.5518, 0.0000],
        [0.2040, 0.7960, 0.0000],
        [0.4984, 0.5016, 0.0000],
        [0.4033, 0.5967, 0.0000],
        [0.4296, 0.5704, 0.0000],
        [0.2413, 0.7587, 0.0000],
        [0.3531, 0.6469, 0.0000],
        [0.4287, 0.5713, 0.0000],
        [0.0830, 0.9170, 0.0000]])
(info) test: tn=168,fp=30/tp=1,fn=2
(info) ROC-AUC: 0.8451178451178452
(info) PRC-AUC: 0.05338826120559866
(info) Processing "data/fold_6"...
(debug) in preprocessing...
(debug) batch_per_epoch=26
(debug) [0] train:    loss=0.7336788085790781,min=1e+99
(debug) [0] validate: tn=18,fp=189/tp=1,fn=0. roc=0.782608695652174,prc=0.010869565217391304,fβ=0.010471204188481674
(debug) [0] watcher: maximal=(0.782608695652174, 0.010869565217391304),count=1
(debug) [0] epoch time=8.660s
(debug) checkpoint saved.
(debug) [1] train:    loss=0.5258308213490707,min=0.7336788085790781
(debug) [1] validate: tn=177,fp=30/tp=0,fn=1. roc=0.642512077294686,prc=0.006666666666666667,fβ=0.0
(debug) [1] watcher: maximal=(0.782608695652174, 0.010869565217391304),count=1
(debug) [1] epoch time=8.685s
(debug) [2] train:    loss=0.4512612005838981,min=0.5258308213490707
(debug) [2] validate: tn=125,fp=82/tp=1,fn=0. roc=0.7053140096618358,prc=0.008064516129032258,fβ=0.02380952380952381
(debug) [2] watcher: maximal=(0.782608695652174, 0.010869565217391304),count=1
(debug) [2] epoch time=8.799s
(debug) [3] train:    loss=0.3565608188509941,min=0.4512612005838981
(debug) [3] validate: tn=95,fp=112/tp=1,fn=0. roc=0.748792270531401,prc=0.009433962264150943,fβ=0.017543859649122806
(debug) [3] watcher: maximal=(0.782608695652174, 0.010869565217391304),count=1
(debug) [3] epoch time=8.953s
(debug) [4] train:    loss=0.3183416798710823,min=0.3565608188509941
(debug) [4] validate: tn=150,fp=57/tp=0,fn=1. roc=0.6473429951690821,prc=0.006756756756756757,fβ=0.0
(debug) [4] watcher: maximal=(0.782608695652174, 0.010869565217391304),count=1
(debug) [4] epoch time=8.999s
(debug) checkpoint loaded.
(debug) in postprocessing...
(debug) tensor([[0.2962, 0.7038, 0.0000],
        [0.4751, 0.5249, 0.0000],
        [0.3464, 0.6536, 0.0000],
        [0.3587, 0.6413, 0.0000],
        [0.2842, 0.7158, 0.0000],
        [0.3461, 0.6539, 0.0000],
        [0.2598, 0.7402, 0.0000],
        [0.4212, 0.5788, 0.0000],
        [0.2811, 0.7189, 0.0000],
        [0.2939, 0.7061, 0.0000],
        [0.2957, 0.7043, 0.0000],
        [0.4358, 0.5642, 0.0000],
        [0.3021, 0.6979, 0.0000],
        [0.2970, 0.7030, 0.0000],
        [0.4208, 0.5792, 0.0000],
        [0.2806, 0.7194, 0.0000],
        [0.2838, 0.7162, 0.0000],
        [0.3228, 0.6772, 0.0000],
        [0.2877, 0.7123, 0.0000],
        [0.3002, 0.6998, 0.0000],
        [0.3010, 0.6990, 0.0000],
        [0.3832, 0.6168, 0.0000],
        [0.2643, 0.7357, 0.0000],
        [0.2770, 0.7230, 0.0000],
        [0.2706, 0.7294, 0.0000],
        [0.2782, 0.7218, 0.0000],
        [0.4146, 0.5854, 0.0000],
        [0.2857, 0.7143, 0.0000],
        [0.4953, 0.5047, 0.0000],
        [0.3489, 0.6511, 0.0000],
        [0.3832, 0.6168, 0.0000],
        [0.3097, 0.6903, 0.0000],
        [0.3045, 0.6955, 0.0000],
        [0.2845, 0.7155, 0.0000],
        [0.2831, 0.7169, 0.0000],
        [0.3178, 0.6822, 0.0000],
        [0.3400, 0.6600, 0.0000],
        [0.2970, 0.7030, 0.0000],
        [0.2958, 0.7042, 0.0000],
        [0.3177, 0.6823, 0.0000],
        [0.2803, 0.7197, 0.0000],
        [0.3831, 0.6169, 0.0000],
        [0.3108, 0.6892, 0.0000],
        [0.2958, 0.7042, 0.0000],
        [0.4443, 0.5557, 0.0000],
        [0.3681, 0.6319, 0.0000],
        [0.3629, 0.6371, 0.0000],
        [0.2789, 0.7211, 0.0000],
        [0.3486, 0.6514, 0.0000],
        [0.4558, 0.5442, 0.0000],
        [0.3018, 0.6982, 0.0000],
        [0.3267, 0.6733, 0.0000],
        [0.3906, 0.6094, 0.0000],
        [0.3183, 0.6817, 0.0000],
        [0.3778, 0.6222, 0.0000],
        [0.3287, 0.6713, 0.0000],
        [0.3835, 0.6165, 0.0000],
        [0.2882, 0.7118, 0.0000],
        [0.4535, 0.5465, 0.0000],
        [0.2968, 0.7032, 0.0000],
        [0.2637, 0.7363, 0.0000],
        [0.2831, 0.7169, 0.0000],
        [0.3372, 0.6628, 1.0000],
        [0.3082, 0.6918, 0.0000],
        [0.3393, 0.6607, 1.0000],
        [0.2871, 0.7129, 0.0000],
        [0.2944, 0.7056, 0.0000],
        [0.4498, 0.5502, 1.0000],
        [0.4229, 0.5771, 1.0000],
        [0.4673, 0.5327, 0.0000],
        [0.3149, 0.6851, 0.0000],
        [0.4796, 0.5204, 0.0000],
        [0.2751, 0.7249, 0.0000],
        [0.3952, 0.6048, 0.0000],
        [0.3686, 0.6314, 0.0000],
        [0.2750, 0.7250, 0.0000],
        [0.3026, 0.6974, 0.0000],
        [0.3756, 0.6244, 0.0000],
        [0.2877, 0.7123, 0.0000],
        [0.4066, 0.5934, 0.0000],
        [0.2782, 0.7218, 0.0000],
        [0.4988, 0.5012, 0.0000],
        [0.2889, 0.7111, 0.0000],
        [0.4638, 0.5362, 0.0000],
        [0.3313, 0.6687, 0.0000],
        [0.3479, 0.6521, 0.0000],
        [0.3391, 0.6609, 0.0000],
        [0.3890, 0.6110, 0.0000],
        [0.3671, 0.6329, 0.0000],
        [0.3574, 0.6426, 0.0000],
        [0.4264, 0.5736, 0.0000],
        [0.4179, 0.5821, 0.0000],
        [0.4129, 0.5871, 0.0000],
        [0.4004, 0.5996, 0.0000],
        [0.3873, 0.6127, 0.0000],
        [0.2969, 0.7031, 0.0000],
        [0.2834, 0.7166, 0.0000],
        [0.2738, 0.7262, 0.0000],
        [0.2990, 0.7010, 0.0000],
        [0.2834, 0.7166, 0.0000],
        [0.3393, 0.6607, 0.0000],
        [0.3307, 0.6693, 0.0000],
        [0.4330, 0.5670, 0.0000],
        [0.2877, 0.7123, 0.0000],
        [0.3721, 0.6279, 0.0000],
        [0.2835, 0.7165, 0.0000],
        [0.2866, 0.7134, 0.0000],
        [0.3090, 0.6910, 0.0000],
        [0.3851, 0.6149, 0.0000],
        [0.2833, 0.7167, 0.0000],
        [0.3435, 0.6565, 0.0000],
        [0.3184, 0.6816, 0.0000],
        [0.4985, 0.5015, 0.0000],
        [0.3498, 0.6502, 0.0000],
        [0.2799, 0.7201, 0.0000],
        [0.3758, 0.6242, 0.0000],
        [0.3001, 0.6999, 0.0000],
        [0.2819, 0.7181, 0.0000],
        [0.2968, 0.7032, 0.0000],
        [0.3131, 0.6869, 0.0000],
        [0.2861, 0.7139, 0.0000],
        [0.2844, 0.7156, 0.0000],
        [0.3823, 0.6177, 0.0000],
        [0.3372, 0.6628, 0.0000],
        [0.3209, 0.6791, 0.0000],
        [0.2548, 0.7452, 0.0000],
        [0.4670, 0.5330, 0.0000],
        [0.3821, 0.6179, 0.0000],
        [0.4339, 0.5661, 0.0000],
        [0.3795, 0.6205, 0.0000],
        [0.3157, 0.6843, 0.0000],
        [0.2760, 0.7240, 0.0000],
        [0.3189, 0.6811, 0.0000],
        [0.3862, 0.6138, 0.0000],
        [0.4109, 0.5891, 0.0000],
        [0.4417, 0.5583, 0.0000],
        [0.3175, 0.6825, 0.0000],
        [0.4783, 0.5217, 0.0000],
        [0.2657, 0.7343, 0.0000],
        [0.2791, 0.7209, 0.0000],
        [0.3753, 0.6247, 0.0000],
        [0.3380, 0.6620, 0.0000],
        [0.3318, 0.6682, 0.0000],
        [0.3482, 0.6518, 0.0000],
        [0.3283, 0.6717, 0.0000],
        [0.3167, 0.6833, 0.0000],
        [0.3014, 0.6986, 0.0000],
        [0.2933, 0.7067, 0.0000],
        [0.3114, 0.6886, 0.0000],
        [0.2815, 0.7185, 0.0000],
        [0.2855, 0.7145, 0.0000],
        [0.3347, 0.6653, 0.0000],
        [0.2923, 0.7077, 0.0000],
        [0.3206, 0.6794, 0.0000],
        [0.2818, 0.7182, 0.0000],
        [0.3734, 0.6266, 0.0000],
        [0.3612, 0.6388, 0.0000],
        [0.3380, 0.6620, 0.0000],
        [0.3968, 0.6032, 0.0000],
        [0.3150, 0.6850, 0.0000],
        [0.2811, 0.7189, 0.0000],
        [0.3003, 0.6997, 0.0000],
        [0.3985, 0.6015, 0.0000],
        [0.4216, 0.5784, 0.0000],
        [0.3198, 0.6802, 0.0000],
        [0.3805, 0.6195, 0.0000],
        [0.3460, 0.6540, 0.0000],
        [0.3403, 0.6597, 0.0000],
        [0.3552, 0.6448, 0.0000],
        [0.3538, 0.6462, 0.0000],
        [0.2886, 0.7114, 0.0000],
        [0.3485, 0.6515, 0.0000],
        [0.3512, 0.6488, 0.0000],
        [0.3388, 0.6612, 0.0000],
        [0.3031, 0.6969, 0.0000],
        [0.3728, 0.6272, 0.0000],
        [0.3675, 0.6325, 0.0000],
        [0.3924, 0.6076, 0.0000],
        [0.2967, 0.7033, 0.0000],
        [0.2859, 0.7141, 0.0000],
        [0.3651, 0.6349, 0.0000],
        [0.4594, 0.5406, 0.0000],
        [0.3442, 0.6558, 0.0000],
        [0.2822, 0.7178, 0.0000],
        [0.3781, 0.6219, 0.0000],
        [0.3295, 0.6705, 0.0000],
        [0.4756, 0.5244, 0.0000],
        [0.2846, 0.7154, 0.0000],
        [0.4050, 0.5950, 0.0000],
        [0.4327, 0.5673, 0.0000],
        [0.2928, 0.7072, 0.0000],
        [0.3711, 0.6289, 0.0000],
        [0.3540, 0.6460, 0.0000],
        [0.3798, 0.6202, 0.0000],
        [0.2800, 0.7200, 0.0000],
        [0.3126, 0.6874, 0.0000],
        [0.3813, 0.6187, 0.0000],
        [0.3131, 0.6869, 0.0000],
        [0.3030, 0.6970, 0.0000],
        [0.3077, 0.6923, 0.0000],
        [0.3768, 0.6232, 0.0000],
        [0.2807, 0.7193, 0.0000],
        [0.2921, 0.7079, 0.0000],
        [0.2557, 0.7443, 0.0000],
        [0.4954, 0.5046, 0.0000],
        [0.3667, 0.6333, 0.0000],
        [0.3065, 0.6935, 0.0000],
        [0.3499, 0.6501, 0.0000],
        [0.3183, 0.6817, 0.0000],
        [0.3858, 0.6142, 0.0000],
        [0.2686, 0.7314, 0.0000],
        [0.3008, 0.6992, 0.0000],
        [0.4351, 0.5649, 0.0000],
        [0.2989, 0.7011, 0.0000],
        [0.4111, 0.5889, 0.0000],
        [0.3068, 0.6932, 0.0000],
        [0.3105, 0.6895, 0.0000],
        [0.3056, 0.6944, 0.0000],
        [0.3351, 0.6649, 0.0000],
        [0.4652, 0.5348, 0.0000],
        [0.3088, 0.6912, 0.0000],
        [0.3218, 0.6782, 0.0000],
        [0.3065, 0.6935, 0.0000],
        [0.2965, 0.7035, 0.0000],
        [0.3078, 0.6922, 0.0000],
        [0.4300, 0.5700, 0.0000],
        [0.3545, 0.6455, 0.0000],
        [0.2854, 0.7146, 0.0000],
        [0.2956, 0.7044, 0.0000],
        [0.4841, 0.5159, 0.0000],
        [0.3837, 0.6163, 0.0000],
        [0.2998, 0.7002, 0.0000],
        [0.3058, 0.6942, 0.0000],
        [0.2847, 0.7153, 0.0000],
        [0.4753, 0.5247, 0.0000],
        [0.3570, 0.6430, 0.0000],
        [0.3078, 0.6922, 0.0000],
        [0.2798, 0.7202, 0.0000],
        [0.3000, 0.7000, 0.0000],
        [0.4292, 0.5708, 0.0000],
        [0.3925, 0.6075, 0.0000],
        [0.2898, 0.7102, 0.0000],
        [0.2940, 0.7060, 0.0000],
        [0.4190, 0.5810, 0.0000],
        [0.3615, 0.6385, 0.0000],
        [0.3025, 0.6975, 0.0000],
        [0.3018, 0.6982, 0.0000],
        [0.3730, 0.6270, 0.0000],
        [0.2831, 0.7169, 0.0000],
        [0.3350, 0.6650, 0.0000],
        [0.3808, 0.6192, 0.0000],
        [0.3007, 0.6993, 0.0000],
        [0.2854, 0.7146, 0.0000],
        [0.3134, 0.6866, 0.0000],
        [0.3150, 0.6850, 0.0000],
        [0.3347, 0.6653, 0.0000]])
(info) test: tn=22,fp=252/tp=4,fn=0
(info) ROC-AUC: 0.31660583941605835
(info) PRC-AUC: 0.009810311707027966
(info) Processing "data/fold_7"...
(debug) in preprocessing...
(debug) batch_per_epoch=27
(debug) [0] train:    loss=0.754706981005492,min=1e+99
(debug) [0] validate: tn=197,fp=0/tp=0,fn=4. roc=0.6700507614213198,prc=0.030389508360944725,fβ=0.0
(debug) [0] watcher: maximal=(0.6700507614213198, 0.030389508360944725),count=1
(debug) [0] epoch time=9.296s
(debug) checkpoint saved.
(debug) [1] train:    loss=0.6552330939858048,min=0.754706981005492
(debug) [1] validate: tn=180,fp=17/tp=1,fn=3. roc=0.9111675126903553,prc=0.0929226802638781,fβ=0.0909090909090909
(debug) [1] watcher: maximal=(0.9111675126903553, 0.0929226802638781),count=2
(debug) [1] epoch time=9.430s
(debug) checkpoint saved.
(debug) [2] train:    loss=0.5392405832255328,min=0.6552330939858048
(debug) [2] validate: tn=157,fp=40/tp=4,fn=0. roc=0.9010152284263959,prc=0.09024441006148323,fβ=0.16666666666666669
(debug) [2] watcher: maximal=(0.9111675126903553, 0.0929226802638781),count=2
(debug) [2] epoch time=9.603s
(debug) [3] train:    loss=0.5002953377034929,min=0.5392405832255328
(debug) [3] validate: tn=170,fp=27/tp=4,fn=0. roc=0.9314720812182741,prc=0.1196721681096681,fβ=0.2285714285714286
(debug) [3] watcher: maximal=(0.9314720812182741, 0.1196721681096681),count=3
(debug) [3] epoch time=9.561s
(debug) checkpoint saved.
(debug) [4] train:    loss=0.5015186844048677,min=0.5002953377034929
(debug) [4] validate: tn=185,fp=12/tp=3,fn=1. roc=0.9238578680203046,prc=0.12289620447515184,fβ=0.31578947368421056
(debug) [4] watcher: maximal=(0.9314720812182741, 0.1196721681096681),count=3
(debug) [4] epoch time=9.548s
(debug) checkpoint loaded.
(debug) in postprocessing...
(debug) tensor([[0.3623, 0.6377, 0.0000],
        [0.0607, 0.9393, 0.0000],
        [0.1549, 0.8451, 0.0000],
        [0.0909, 0.9091, 0.0000],
        [0.4929, 0.5071, 0.0000],
        [0.0479, 0.9521, 0.0000],
        [0.0469, 0.9531, 0.0000],
        [0.3115, 0.6885, 0.0000],
        [0.1467, 0.8533, 0.0000],
        [0.1843, 0.8157, 0.0000],
        [0.4218, 0.5782, 0.0000],
        [0.0487, 0.9513, 0.0000],
        [0.3456, 0.6544, 0.0000],
        [0.1138, 0.8862, 0.0000],
        [0.4924, 0.5076, 0.0000],
        [0.0795, 0.9205, 0.0000],
        [0.0462, 0.9538, 0.0000],
        [0.1997, 0.8003, 0.0000],
        [0.0578, 0.9422, 0.0000],
        [0.0474, 0.9526, 0.0000],
        [0.0592, 0.9408, 0.0000],
        [0.0467, 0.9533, 0.0000],
        [0.0464, 0.9536, 0.0000],
        [0.4470, 0.5530, 0.0000],
        [0.2188, 0.7812, 0.0000],
        [0.0551, 0.9449, 0.0000],
        [0.2800, 0.7200, 0.0000],
        [0.1579, 0.8421, 0.0000],
        [0.0465, 0.9535, 0.0000],
        [0.1808, 0.8192, 0.0000],
        [0.1463, 0.8537, 0.0000],
        [0.0484, 0.9516, 0.0000],
        [0.0817, 0.9183, 0.0000],
        [0.0720, 0.9280, 0.0000],
        [0.2170, 0.7830, 0.0000],
        [0.3956, 0.6044, 0.0000],
        [0.4577, 0.5423, 0.0000],
        [0.0906, 0.9094, 0.0000],
        [0.0467, 0.9533, 0.0000],
        [0.0488, 0.9512, 0.0000],
        [0.0717, 0.9283, 0.0000],
        [0.4077, 0.5923, 0.0000],
        [0.2470, 0.7530, 0.0000],
        [0.0976, 0.9024, 0.0000],
        [0.0469, 0.9531, 0.0000],
        [0.0500, 0.9500, 0.0000],
        [0.4094, 0.5906, 0.0000],
        [0.3517, 0.6483, 0.0000],
        [0.0567, 0.9433, 0.0000],
        [0.3053, 0.6947, 0.0000],
        [0.2027, 0.7973, 0.0000],
        [0.1075, 0.8925, 0.0000],
        [0.4335, 0.5665, 0.0000],
        [0.0856, 0.9144, 0.0000],
        [0.3171, 0.6829, 0.0000],
        [0.2263, 0.7737, 0.0000],
        [0.2833, 0.7167, 0.0000],
        [0.0706, 0.9294, 0.0000],
        [0.4390, 0.5610, 0.0000],
        [0.2800, 0.7200, 0.0000],
        [0.1046, 0.8954, 0.0000],
        [0.0501, 0.9499, 0.0000],
        [0.2098, 0.7902, 0.0000],
        [0.0464, 0.9536, 0.0000],
        [0.0466, 0.9534, 0.0000],
        [0.0469, 0.9531, 0.0000],
        [0.1129, 0.8871, 0.0000],
        [0.2134, 0.7866, 0.0000]])
(info) test: tn=139,fp=68/tp=0,fn=1
(info) ROC-AUC: 0.6038647342995169
(info) PRC-AUC: 0.006024096385542169
(info) Processing "data/fold_8"...
(debug) in preprocessing...
(debug) batch_per_epoch=27
(debug) [0] train:    loss=0.7370220246138396,min=1e+99
(debug) [0] validate: tn=193,fp=6/tp=1,fn=2. roc=0.8693467336683417,prc=0.058678400783663945,fβ=0.2
(debug) [0] watcher: maximal=(0.8693467336683417, 0.058678400783663945),count=1
(debug) [0] epoch time=9.308s
(debug) checkpoint saved.
(debug) [1] train:    loss=0.6305506571575448,min=0.7370220246138396
(debug) [1] validate: tn=122,fp=77/tp=3,fn=0. roc=0.862646566164154,prc=0.05813510140077851,fβ=0.07228915662650602
(debug) [1] watcher: maximal=(0.8693467336683417, 0.058678400783663945),count=1
(debug) [1] epoch time=9.058s
(debug) [2] train:    loss=0.5814149600488169,min=0.6305506571575448
(debug) [2] validate: tn=149,fp=50/tp=2,fn=1. roc=0.8542713567839196,prc=0.05847642307131763,fβ=0.07272727272727274
(debug) [2] watcher: maximal=(0.8693467336683417, 0.058678400783663945),count=1
(debug) [2] epoch time=9.321s
(debug) [3] train:    loss=0.4760324513470685,min=0.5814149600488169
(debug) [3] validate: tn=176,fp=23/tp=1,fn=2. roc=0.897822445561139,prc=0.06284764618097952,fβ=0.07407407407407407
(debug) [3] watcher: maximal=(0.897822445561139, 0.06284764618097952),count=2
(debug) [3] epoch time=9.365s
(debug) checkpoint saved.
(debug) [4] train:    loss=0.4193858427030069,min=0.4760324513470685
(debug) [4] validate: tn=162,fp=37/tp=3,fn=0. roc=0.8944723618090453,prc=0.0603509612757509,fβ=0.13953488372093023
(debug) [4] watcher: maximal=(0.897822445561139, 0.06284764618097952),count=2
(debug) [4] epoch time=9.498s
(debug) checkpoint loaded.
(debug) in postprocessing...
(debug) tensor([[0.0908, 0.9092, 0.0000],
        [0.0975, 0.9025, 0.0000],
        [0.4993, 0.5007, 0.0000],
        [0.4614, 0.5386, 0.0000],
        [0.3964, 0.6036, 0.0000],
        [0.4803, 0.5197, 0.0000],
        [0.1431, 0.8569, 0.0000],
        [0.4584, 0.5416, 0.0000],
        [0.4196, 0.5804, 0.0000],
        [0.0718, 0.9282, 0.0000],
        [0.3559, 0.6441, 0.0000],
        [0.1707, 0.8293, 1.0000],
        [0.2911, 0.7089, 1.0000],
        [0.0752, 0.9248, 0.0000],
        [0.5000, 0.5000, 0.0000],
        [0.4526, 0.5474, 0.0000],
        [0.4841, 0.5159, 0.0000],
        [0.0763, 0.9237, 1.0000],
        [0.1459, 0.8541, 0.0000],
        [0.1086, 0.8914, 0.0000],
        [0.3115, 0.6885, 0.0000],
        [0.2649, 0.7351, 0.0000]])
(info) test: tn=178,fp=19/tp=3,fn=1
(info) ROC-AUC: 0.947969543147208
(info) PRC-AUC: 0.17590638528138527
(info) Processing "data/fold_9"...
(debug) in preprocessing...
(debug) batch_per_epoch=27
(debug) [0] train:    loss=0.7731450111777695,min=1e+99
(debug) [0] validate: tn=0,fp=196/tp=5,fn=0. roc=0.27448979591836736,prc=0.015586151909429,fβ=0.04854368932038835
(debug) [0] watcher: maximal=(0.27448979591836736, 0.015586151909429),count=1
(debug) [0] epoch time=9.405s
(debug) checkpoint saved.
(debug) [1] train:    loss=0.6904637813568115,min=0.7731450111777695
(debug) [1] validate: tn=124,fp=72/tp=2,fn=3. roc=0.4163265306122449,prc=0.02338056186253948,fβ=0.05063291139240506
(debug) [1] watcher: maximal=(0.4163265306122449, 0.02338056186253948),count=2
(debug) [1] epoch time=9.375s
(debug) checkpoint saved.
(debug) [2] train:    loss=0.5833057518358584,min=0.6904637813568115
(debug) [2] validate: tn=175,fp=21/tp=2,fn=3. roc=0.49489795918367346,prc=0.05506413098306038,fβ=0.14285714285714285
(debug) [2] watcher: maximal=(0.49489795918367346, 0.05506413098306038),count=3
(debug) [2] epoch time=9.515s
(debug) checkpoint saved.
(debug) [3] train:    loss=0.4959632290734185,min=0.5833057518358584
(debug) [3] validate: tn=178,fp=18/tp=2,fn=3. roc=0.4744897959183673,prc=0.05051536389496057,fβ=0.16000000000000003
(debug) [3] watcher: maximal=(0.49489795918367346, 0.05506413098306038),count=3
(debug) [3] epoch time=9.389s
(debug) [4] train:    loss=0.45996807129294787,min=0.4959632290734185
(debug) [4] validate: tn=152,fp=44/tp=2,fn=3. roc=0.47653061224489796,prc=0.059505968642712966,fβ=0.0784313725490196
(debug) [4] watcher: maximal=(0.49489795918367346, 0.05506413098306038),count=3
(debug) [4] epoch time=9.427s
(debug) checkpoint loaded.
(debug) in postprocessing...
(debug) tensor([[0.3621, 0.6379, 0.0000],
        [0.3980, 0.6020, 0.0000],
        [0.3256, 0.6744, 0.0000],
        [0.3783, 0.6217, 0.0000],
        [0.4761, 0.5239, 0.0000],
        [0.3819, 0.6181, 0.0000],
        [0.3397, 0.6603, 0.0000],
        [0.4027, 0.5973, 0.0000],
        [0.3733, 0.6267, 0.0000],
        [0.4351, 0.5649, 0.0000],
        [0.3646, 0.6354, 0.0000],
        [0.3777, 0.6223, 0.0000],
        [0.3196, 0.6804, 1.0000],
        [0.3391, 0.6609, 0.0000],
        [0.3571, 0.6429, 0.0000],
        [0.3116, 0.6884, 0.0000],
        [0.4012, 0.5988, 0.0000],
        [0.3890, 0.6110, 0.0000],
        [0.3178, 0.6822, 0.0000],
        [0.3027, 0.6973, 0.0000],
        [0.3135, 0.6865, 0.0000]])
(info) test: tn=179,fp=20/tp=1,fn=2
(info) ROC-AUC: 0.8877721943048575
(info) PRC-AUC: 0.07245794329127662
(info) roc = [0.6602, 0.7933, 0.9201, 0.6679, 0.8641, 0.8451, 0.3166, 0.6039, 0.948, 0.8878]
(info) prc = [0.0646, 0.2383, 0.1274, 0.2801, 0.2818, 0.0534, 0.0098, 0.006, 0.1759, 0.0725]
(info) All folds: ROC-AUC = 0.751±0.193, PRC-AUC = 0.131±0.107